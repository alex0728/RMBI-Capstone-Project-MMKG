{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd39f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from os import makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cccf188b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LabelName</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/027rn</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>The Dominican Republic is a country located on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/017dcd</td>\n",
       "      <td>Mighty Morphin Power Rangers</td>\n",
       "      <td>Mighty Morphin Power Rangers is an American su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/01sl1q</td>\n",
       "      <td>Michelle Rodriguez</td>\n",
       "      <td>Mayte Michelle Rodriguez is an American actres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/0cnk2q</td>\n",
       "      <td>Australia national football team</td>\n",
       "      <td>The Australia men's national soccer team repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/02_j1w</td>\n",
       "      <td>Defender</td>\n",
       "      <td>In the sport of association football, a defend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14179</th>\n",
       "      <td>/m/0dlj8q2</td>\n",
       "      <td>Le Monde's 100 Books of the Century</td>\n",
       "      <td>The 100 Books of the Century is a list of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14180</th>\n",
       "      <td>/m/05zp8</td>\n",
       "      <td>Palace</td>\n",
       "      <td>A palace is a grand residence, especially a ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14181</th>\n",
       "      <td>/m/024030</td>\n",
       "      <td>Padma Vibhushan</td>\n",
       "      <td>The Padma Vibhushan is the second-highest civi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14182</th>\n",
       "      <td>/m/02y_9cf</td>\n",
       "      <td>Ethiopian Empire</td>\n",
       "      <td>The Ethiopian Empire, also formerly known by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14183</th>\n",
       "      <td>/m/0fkrk</td>\n",
       "      <td>Grasses</td>\n",
       "      <td>Poaceae or Gramineae is a large and nearly ubi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14184 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        LabelName                                 name  \\\n",
       "0        /m/027rn                   Dominican Republic   \n",
       "1       /m/017dcd         Mighty Morphin Power Rangers   \n",
       "2       /m/01sl1q                   Michelle Rodriguez   \n",
       "3       /m/0cnk2q     Australia national football team   \n",
       "4       /m/02_j1w                             Defender   \n",
       "...           ...                                  ...   \n",
       "14179  /m/0dlj8q2  Le Monde's 100 Books of the Century   \n",
       "14180    /m/05zp8                               Palace   \n",
       "14181   /m/024030                      Padma Vibhushan   \n",
       "14182  /m/02y_9cf                     Ethiopian Empire   \n",
       "14183    /m/0fkrk                              Grasses   \n",
       "\n",
       "                                             description  \n",
       "0      The Dominican Republic is a country located on...  \n",
       "1      Mighty Morphin Power Rangers is an American su...  \n",
       "2      Mayte Michelle Rodriguez is an American actres...  \n",
       "3      The Australia men's national soccer team repre...  \n",
       "4      In the sport of association football, a defend...  \n",
       "...                                                  ...  \n",
       "14179  The 100 Books of the Century is a list of the ...  \n",
       "14180  A palace is a grand residence, especially a ro...  \n",
       "14181  The Padma Vibhushan is the second-highest civi...  \n",
       "14182  The Ethiopian Empire, also formerly known by t...  \n",
       "14183  Poaceae or Gramineae is a large and nearly ubi...  \n",
       "\n",
       "[14184 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_des = pd.read_csv('D:\\RMBI_MMKG_data\\img_des.csv')\n",
    "img_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23646b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb92fb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LabelName</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/027rn</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>The Dominican Republic is a country located on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/017dcd</td>\n",
       "      <td>Mighty Morphin Power Rangers</td>\n",
       "      <td>Mighty Morphin Power Rangers is an American su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/01sl1q</td>\n",
       "      <td>Michelle Rodriguez</td>\n",
       "      <td>Mayte Michelle Rodriguez is an American actres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/0cnk2q</td>\n",
       "      <td>Australia national football team</td>\n",
       "      <td>The Australia men's national soccer team repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/02_j1w</td>\n",
       "      <td>Defender</td>\n",
       "      <td>In the sport of association football, a defend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>/m/01b9ck</td>\n",
       "      <td>Darryl F. Zanuck</td>\n",
       "      <td>Darryl Francis Zanuck was an American film pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>/m/011ywj</td>\n",
       "      <td>Gosford Park</td>\n",
       "      <td>Gosford Park is a 2001 satirical black comedy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>/m/0325pb</td>\n",
       "      <td>Alpha Delta Pi</td>\n",
       "      <td>Alpha Delta Pi, commonly known as ADPi, is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>/m/0mnrb</td>\n",
       "      <td>Henrico County</td>\n",
       "      <td>Henrico County, officially the County of Henri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>/m/05sxg2</td>\n",
       "      <td>Theatrical producer</td>\n",
       "      <td>A theatrical producer is a person who oversees...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LabelName                              name  \\\n",
       "0     /m/027rn                Dominican Republic   \n",
       "1    /m/017dcd      Mighty Morphin Power Rangers   \n",
       "2    /m/01sl1q                Michelle Rodriguez   \n",
       "3    /m/0cnk2q  Australia national football team   \n",
       "4    /m/02_j1w                          Defender   \n",
       "..         ...                               ...   \n",
       "995  /m/01b9ck                  Darryl F. Zanuck   \n",
       "996  /m/011ywj                      Gosford Park   \n",
       "997  /m/0325pb                    Alpha Delta Pi   \n",
       "998   /m/0mnrb                    Henrico County   \n",
       "999  /m/05sxg2               Theatrical producer   \n",
       "\n",
       "                                           description  \n",
       "0    The Dominican Republic is a country located on...  \n",
       "1    Mighty Morphin Power Rangers is an American su...  \n",
       "2    Mayte Michelle Rodriguez is an American actres...  \n",
       "3    The Australia men's national soccer team repre...  \n",
       "4    In the sport of association football, a defend...  \n",
       "..                                                 ...  \n",
       "995  Darryl Francis Zanuck was an American film pro...  \n",
       "996  Gosford Park is a 2001 satirical black comedy ...  \n",
       "997  Alpha Delta Pi, commonly known as ADPi, is an ...  \n",
       "998  Henrico County, officially the County of Henri...  \n",
       "999  A theatrical producer is a person who oversees...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_des_trunc = img_des.head(SIZE)\n",
    "img_des_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0464e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LabelName</th>\n",
       "      <th>name</th>\n",
       "      <th>title_vec</th>\n",
       "      <th>des_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/027rn</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/017dcd</td>\n",
       "      <td>Mighty Morphin Power Rangers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/01sl1q</td>\n",
       "      <td>Michelle Rodriguez</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/0cnk2q</td>\n",
       "      <td>Australia national football team</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/02_j1w</td>\n",
       "      <td>Defender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>/m/01b9ck</td>\n",
       "      <td>Darryl F. Zanuck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>/m/011ywj</td>\n",
       "      <td>Gosford Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>/m/0325pb</td>\n",
       "      <td>Alpha Delta Pi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>/m/0mnrb</td>\n",
       "      <td>Henrico County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>/m/05sxg2</td>\n",
       "      <td>Theatrical producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LabelName                              name title_vec des_vec\n",
       "0     /m/027rn                Dominican Republic       NaN     NaN\n",
       "1    /m/017dcd      Mighty Morphin Power Rangers       NaN     NaN\n",
       "2    /m/01sl1q                Michelle Rodriguez       NaN     NaN\n",
       "3    /m/0cnk2q  Australia national football team       NaN     NaN\n",
       "4    /m/02_j1w                          Defender       NaN     NaN\n",
       "..         ...                               ...       ...     ...\n",
       "995  /m/01b9ck                  Darryl F. Zanuck       NaN     NaN\n",
       "996  /m/011ywj                      Gosford Park       NaN     NaN\n",
       "997  /m/0325pb                    Alpha Delta Pi       NaN     NaN\n",
       "998   /m/0mnrb                    Henrico County       NaN     NaN\n",
       "999  /m/05sxg2               Theatrical producer       NaN     NaN\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec = pd.DataFrame(columns=['LabelName','name','title_vec','des_vec'])\n",
    "text_vec['LabelName'] = img_des_trunc['LabelName']\n",
    "text_vec['name'] = img_des_trunc['name']\n",
    "text_vec['title_vec']=text_vec['title_vec'].astype(object)\n",
    "text_vec['des_vec']=text_vec['des_vec'].astype(object)\n",
    "text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a034f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LabelName</th>\n",
       "      <th>name</th>\n",
       "      <th>title_vec</th>\n",
       "      <th>des_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/027rn</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>[0.4945737, 1.3592469, 1.282383, 0.01269114, -...</td>\n",
       "      <td>[0.7342588, -0.70393395, 1.6656038, 0.67461014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/017dcd</td>\n",
       "      <td>Mighty Morphin Power Rangers</td>\n",
       "      <td>[1.6969184, 1.8559471, 0.8122708, -0.40268016,...</td>\n",
       "      <td>[0.025732398, -0.7696621, 2.172137, 1.2750009,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/01sl1q</td>\n",
       "      <td>Michelle Rodriguez</td>\n",
       "      <td>[1.2370641, 2.8018966, 0.16598952, -0.5138393,...</td>\n",
       "      <td>[0.6779196, -0.15636724, 0.9539355, 0.6223599,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/0cnk2q</td>\n",
       "      <td>Australia national football team</td>\n",
       "      <td>[-0.34985536, 1.8396395, 1.8012114, -0.3399124...</td>\n",
       "      <td>[-0.7440083, 0.010402456, 2.7207577, 0.6726733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/02_j1w</td>\n",
       "      <td>Defender</td>\n",
       "      <td>[0.10609877, 1.8506274, 1.07485, -0.12472837, ...</td>\n",
       "      <td>[-0.1949073, -0.38760465, 3.056767, 0.1185953,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>/m/01b9ck</td>\n",
       "      <td>Darryl F. Zanuck</td>\n",
       "      <td>[1.229999, 2.4127681, 0.94314957, -1.3280284, ...</td>\n",
       "      <td>[0.73823285, -0.08005962, 0.827093, 0.8234503,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>/m/011ywj</td>\n",
       "      <td>Gosford Park</td>\n",
       "      <td>[0.7568916, 1.5736562, 0.8222938, -0.13049412,...</td>\n",
       "      <td>[0.26722866, -0.9173725, 1.927658, 0.5772505, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>/m/0325pb</td>\n",
       "      <td>Alpha Delta Pi</td>\n",
       "      <td>[0.5692497, 1.3098, 1.3415865, -0.55102956, -0...</td>\n",
       "      <td>[0.18281287, -0.25513795, 2.1837523, 0.3496461...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>/m/0mnrb</td>\n",
       "      <td>Henrico County</td>\n",
       "      <td>[0.059751034, 0.558505, 0.9079651, -0.01371228...</td>\n",
       "      <td>[-0.95366466, -0.1571609, 1.9237427, -0.214625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>/m/05sxg2</td>\n",
       "      <td>Theatrical producer</td>\n",
       "      <td>[0.7791275, 1.6730425, 0.708414, -0.34585774, ...</td>\n",
       "      <td>[0.7939751, 0.95126754, 0.88291603, 1.622468, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LabelName                              name  \\\n",
       "0     /m/027rn                Dominican Republic   \n",
       "1    /m/017dcd      Mighty Morphin Power Rangers   \n",
       "2    /m/01sl1q                Michelle Rodriguez   \n",
       "3    /m/0cnk2q  Australia national football team   \n",
       "4    /m/02_j1w                          Defender   \n",
       "..         ...                               ...   \n",
       "995  /m/01b9ck                  Darryl F. Zanuck   \n",
       "996  /m/011ywj                      Gosford Park   \n",
       "997  /m/0325pb                    Alpha Delta Pi   \n",
       "998   /m/0mnrb                    Henrico County   \n",
       "999  /m/05sxg2               Theatrical producer   \n",
       "\n",
       "                                             title_vec  \\\n",
       "0    [0.4945737, 1.3592469, 1.282383, 0.01269114, -...   \n",
       "1    [1.6969184, 1.8559471, 0.8122708, -0.40268016,...   \n",
       "2    [1.2370641, 2.8018966, 0.16598952, -0.5138393,...   \n",
       "3    [-0.34985536, 1.8396395, 1.8012114, -0.3399124...   \n",
       "4    [0.10609877, 1.8506274, 1.07485, -0.12472837, ...   \n",
       "..                                                 ...   \n",
       "995  [1.229999, 2.4127681, 0.94314957, -1.3280284, ...   \n",
       "996  [0.7568916, 1.5736562, 0.8222938, -0.13049412,...   \n",
       "997  [0.5692497, 1.3098, 1.3415865, -0.55102956, -0...   \n",
       "998  [0.059751034, 0.558505, 0.9079651, -0.01371228...   \n",
       "999  [0.7791275, 1.6730425, 0.708414, -0.34585774, ...   \n",
       "\n",
       "                                               des_vec  \n",
       "0    [0.7342588, -0.70393395, 1.6656038, 0.67461014...  \n",
       "1    [0.025732398, -0.7696621, 2.172137, 1.2750009,...  \n",
       "2    [0.6779196, -0.15636724, 0.9539355, 0.6223599,...  \n",
       "3    [-0.7440083, 0.010402456, 2.7207577, 0.6726733...  \n",
       "4    [-0.1949073, -0.38760465, 3.056767, 0.1185953,...  \n",
       "..                                                 ...  \n",
       "995  [0.73823285, -0.08005962, 0.827093, 0.8234503,...  \n",
       "996  [0.26722866, -0.9173725, 1.927658, 0.5772505, ...  \n",
       "997  [0.18281287, -0.25513795, 2.1837523, 0.3496461...  \n",
       "998  [-0.95366466, -0.1571609, 1.9237427, -0.214625...  \n",
       "999  [0.7939751, 0.95126754, 0.88291603, 1.622468, ...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sister\n",
    "sentence_embedding = sister.BertEmbedding(lang=\"en\")\n",
    "\n",
    "for i in range(SIZE):\n",
    "    if (pd.notnull(img_des_trunc['name'][i])):\n",
    "        text_vec['title_vec'][i] = sentence_embedding(img_des_trunc['name'][i])\n",
    "    if (pd.notnull(img_des_trunc['description'][i])):\n",
    "        text_vec['des_vec'][i] = sentence_embedding(img_des_trunc['description'][i]) \n",
    "text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307c65e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [0.7342588, -0.70393395, 1.6656038, 0.67461014...\n",
       "1      [0.025732398, -0.7696621, 2.172137, 1.2750009,...\n",
       "2      [0.6779196, -0.15636724, 0.9539355, 0.6223599,...\n",
       "3      [-0.7440083, 0.010402456, 2.7207577, 0.6726733...\n",
       "4      [-0.1949073, -0.38760465, 3.056767, 0.1185953,...\n",
       "                             ...                        \n",
       "995    [0.73823285, -0.08005962, 0.827093, 0.8234503,...\n",
       "996    [0.26722866, -0.9173725, 1.927658, 0.5772505, ...\n",
       "997    [0.18281287, -0.25513795, 2.1837523, 0.3496461...\n",
       "998    [-0.95366466, -0.1571609, 1.9237427, -0.214625...\n",
       "999    [0.7939751, 0.95126754, 0.88291603, 1.622468, ...\n",
       "Name: des_vec, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec['des_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89721b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:819: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\World War II\\CG-lQt2UIAAMHnz.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Crystal Palace F.C.\\DNPRuwzW4AEATin.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Crystal Palace F.C.\\DXIZ3FtX0AARZs-.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\United Nations\\C-SBcq9XYAACzDM.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Marvel Entertainment\\BO_SLlbCQAAhW3o.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Billy Connolly\\DqA-b32WsAAYAIU.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\APOEL FC\\DBuISFIXsAYsLy-.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Fayetteville\\DWaC5hiVQAIoGLU.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\SG Dynamo Dresden\\DjliQpmXcAExxHJ.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Shrek\\CG0LV7KWcAABHbU.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Dan Povenmire\\DKC4jwsUQAAxtSs.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Election\\CwtiPuWUkAEXeSY.jpg\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "x_img = []\n",
    "x_title = []\n",
    "x_des = []\n",
    "import os\n",
    "\n",
    "for i in range(SIZE):\n",
    "    path_of_the_directory = os.path.join('D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader', img_des['name'][i])\n",
    "    ext = ('.jpg')\n",
    "    for path, dirc, files in os.walk(path_of_the_directory):\n",
    "        for name in files:\n",
    "            if name.endswith(ext):\n",
    "                \n",
    "                img_path = os.path.join(path, name)\n",
    "                try:                \n",
    "                    img = image.load_img(img_path, target_size=(224, 224))\n",
    "                    img = image.img_to_array(img)\n",
    "                \n",
    "                    x_img.append(img)\n",
    "                    y.append(img_des['name'][i])\n",
    "                    x_title.append(text_vec['title_vec'][i])\n",
    "                    x_des.append(text_vec['des_vec'][i])\n",
    "                except:\n",
    "                    print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "893b3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "x_img = np.array(x_img)\n",
    "x_title = np.array(x_title)\n",
    "x_des = np.array(x_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b355ccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8493,)\n",
      "(8493, 224, 224, 3)\n",
      "(8493, 768)\n",
      "(8493, 768)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(x_img.shape)\n",
    "print(x_title.shape)\n",
    "print(x_des.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "608e2411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dominican Republic', 'Dominican Republic', 'Dominican Republic',\n",
       "       ..., 'Theatrical producer', 'Theatrical producer',\n",
       "       'Theatrical producer'], dtype='<U97')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0096a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y_encoded = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a30e1218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([265, 265, 265, ..., 890, 890, 890])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a1aca36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e42d8087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8493, 983)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1e78273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_img_train, x_img_test, x_title_train, x_title_test,x_des_train, x_des_test, y_one_hot_train, y_one_hot_test, y_encoded_train, y_encoded_test = train_test_split(x_img, x_title, x_des, y_one_hot, y_encoded, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c1b5399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[112., 110., 111.],\n",
       "         [122., 120., 121.],\n",
       "         [111., 109., 110.],\n",
       "         ...,\n",
       "         [220., 220., 220.],\n",
       "         [223., 223., 225.],\n",
       "         [223., 223., 225.]],\n",
       "\n",
       "        [[184., 182., 183.],\n",
       "         [197., 195., 196.],\n",
       "         [206., 204., 205.],\n",
       "         ...,\n",
       "         [221., 221., 221.],\n",
       "         [223., 223., 225.],\n",
       "         [223., 223., 225.]],\n",
       "\n",
       "        [[193., 191., 192.],\n",
       "         [190., 188., 189.],\n",
       "         [176., 174., 175.],\n",
       "         ...,\n",
       "         [231., 231., 231.],\n",
       "         [223., 223., 225.],\n",
       "         [223., 223., 225.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 10.,  10.,  10.],\n",
       "         [ 17.,  17.,  17.],\n",
       "         [134., 134., 134.],\n",
       "         ...,\n",
       "         [160., 205., 172.],\n",
       "         [148., 189., 155.],\n",
       "         [202., 230., 207.]],\n",
       "\n",
       "        [[  2.,   2.,   2.],\n",
       "         [  0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.],\n",
       "         ...,\n",
       "         [196., 224., 199.],\n",
       "         [118., 155., 124.],\n",
       "         [215., 249., 224.]],\n",
       "\n",
       "        [[  3.,   3.,   3.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  0.,   0.,   0.],\n",
       "         ...,\n",
       "         [216., 218., 213.],\n",
       "         [211., 229., 217.],\n",
       "         [159., 187., 172.]]],\n",
       "\n",
       "\n",
       "       [[[ 45.,  46.,  41.],\n",
       "         [207., 207., 205.],\n",
       "         [ 55.,  56.,  50.],\n",
       "         ...,\n",
       "         [152., 151., 156.],\n",
       "         [178., 178., 178.],\n",
       "         [191., 191., 191.]],\n",
       "\n",
       "        [[ 33.,  34.,  29.],\n",
       "         [208., 208., 206.],\n",
       "         [112., 113., 107.],\n",
       "         ...,\n",
       "         [173., 173., 173.],\n",
       "         [195., 195., 195.],\n",
       "         [186., 186., 186.]],\n",
       "\n",
       "        [[191., 191., 189.],\n",
       "         [141., 142., 136.],\n",
       "         [ 58.,  60.,  47.],\n",
       "         ...,\n",
       "         [192., 192., 192.],\n",
       "         [189., 189., 189.],\n",
       "         [179., 179., 179.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 16.,  15.,  59.],\n",
       "         [ 77.,  77.,  89.],\n",
       "         [ 24.,  25.,  55.],\n",
       "         ...,\n",
       "         [ 30.,  29.,  61.],\n",
       "         [ 47.,  49.,  74.],\n",
       "         [ 48.,  45.,  72.]],\n",
       "\n",
       "        [[ 14.,  12.,  59.],\n",
       "         [  9.,   8.,  52.],\n",
       "         [ 10.,   8.,  57.],\n",
       "         ...,\n",
       "         [ 21.,  21.,  57.],\n",
       "         [ 35.,  37.,  62.],\n",
       "         [ 23.,  22.,  62.]],\n",
       "\n",
       "        [[  8.,   6.,  55.],\n",
       "         [  9.,   7.,  57.],\n",
       "         [  9.,   7.,  56.],\n",
       "         ...,\n",
       "         [  7.,   7.,  57.],\n",
       "         [  7.,   5.,  55.],\n",
       "         [  8.,   6.,  55.]]],\n",
       "\n",
       "\n",
       "       [[[184., 220., 220.],\n",
       "         [198., 229., 223.],\n",
       "         [165., 204., 203.],\n",
       "         ...,\n",
       "         [ 43.,  79.,  77.],\n",
       "         [ 42.,  59.,  53.],\n",
       "         [ 36.,  58.,  46.]],\n",
       "\n",
       "        [[220., 237., 227.],\n",
       "         [237., 243., 233.],\n",
       "         [223., 243., 232.],\n",
       "         ...,\n",
       "         [ 62.,  96.,  82.],\n",
       "         [ 37.,  54.,  48.],\n",
       "         [ 36.,  58.,  45.]],\n",
       "\n",
       "        [[228., 239., 231.],\n",
       "         [234., 239., 233.],\n",
       "         [228., 238., 229.],\n",
       "         ...,\n",
       "         [ 71., 105.,  88.],\n",
       "         [ 42.,  59.,  49.],\n",
       "         [ 37.,  59.,  47.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 50.,  55.,  51.],\n",
       "         [ 40.,  46.,  46.],\n",
       "         [ 38.,  46.,  49.],\n",
       "         ...,\n",
       "         [ 28.,  38.,  27.],\n",
       "         [ 40.,  65.,  59.],\n",
       "         [ 19.,  39.,  30.]],\n",
       "\n",
       "        [[ 54.,  56.,  53.],\n",
       "         [ 39.,  45.,  43.],\n",
       "         [ 37.,  45.,  47.],\n",
       "         ...,\n",
       "         [ 22.,  39.,  31.],\n",
       "         [ 48.,  74.,  71.],\n",
       "         [ 34.,  50.,  47.]],\n",
       "\n",
       "        [[ 51.,  53.,  50.],\n",
       "         [ 40.,  46.,  46.],\n",
       "         [ 38.,  47.,  44.],\n",
       "         ...,\n",
       "         [ 33.,  52.,  46.],\n",
       "         [ 31.,  51.,  50.],\n",
       "         [ 24.,  36.,  36.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[112., 105., 112.],\n",
       "         [111., 105., 109.],\n",
       "         [111., 102., 103.],\n",
       "         ...,\n",
       "         [149., 134., 115.],\n",
       "         [124., 112.,  90.],\n",
       "         [139., 123., 108.]],\n",
       "\n",
       "        [[118., 109., 114.],\n",
       "         [116., 107., 110.],\n",
       "         [114., 104., 103.],\n",
       "         ...,\n",
       "         [141., 130., 108.],\n",
       "         [167., 156., 128.],\n",
       "         [186., 166., 142.]],\n",
       "\n",
       "        [[126., 117., 120.],\n",
       "         [125., 114., 118.],\n",
       "         [127., 117., 115.],\n",
       "         ...,\n",
       "         [ 56.,  52.,  14.],\n",
       "         [ 50.,  50.,  14.],\n",
       "         [ 48.,  45.,  12.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 66.,  55.,  51.],\n",
       "         [ 66.,  55.,  51.],\n",
       "         [ 68.,  57.,  53.],\n",
       "         ...,\n",
       "         [ 87.,  68.,  62.],\n",
       "         [ 88.,  69.,  63.],\n",
       "         [ 84.,  65.,  59.]],\n",
       "\n",
       "        [[ 64.,  53.,  49.],\n",
       "         [ 65.,  54.,  50.],\n",
       "         [ 65.,  54.,  50.],\n",
       "         ...,\n",
       "         [ 84.,  67.,  60.],\n",
       "         [ 83.,  66.,  59.],\n",
       "         [ 83.,  66.,  59.]],\n",
       "\n",
       "        [[ 63.,  52.,  48.],\n",
       "         [ 65.,  54.,  50.],\n",
       "         [ 65.,  54.,  50.],\n",
       "         ...,\n",
       "         [ 81.,  64.,  57.],\n",
       "         [ 80.,  63.,  56.],\n",
       "         [ 80.,  63.,  56.]]],\n",
       "\n",
       "\n",
       "       [[[255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         ...,\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.]],\n",
       "\n",
       "        [[255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         ...,\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.]],\n",
       "\n",
       "        [[255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         ...,\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         ...,\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.]],\n",
       "\n",
       "        [[255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         ...,\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.]],\n",
       "\n",
       "        [[255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         ...,\n",
       "         [255., 211.,   2.],\n",
       "         [255., 211.,   2.],\n",
       "         [255., 210.,   3.]]],\n",
       "\n",
       "\n",
       "       [[[ 42.,  28.,  15.],\n",
       "         [ 55.,  40.,  19.],\n",
       "         [ 52.,  36.,  21.],\n",
       "         ...,\n",
       "         [109., 102.,  92.],\n",
       "         [107., 102.,  72.],\n",
       "         [ 95.,  88.,  70.]],\n",
       "\n",
       "        [[ 45.,  32.,  16.],\n",
       "         [ 45.,  30.,   9.],\n",
       "         [ 60.,  45.,  26.],\n",
       "         ...,\n",
       "         [106., 100.,  86.],\n",
       "         [107.,  96.,  74.],\n",
       "         [100.,  88.,  74.]],\n",
       "\n",
       "        [[ 47.,  31.,  16.],\n",
       "         [ 53.,  38.,  15.],\n",
       "         [ 50.,  35.,  14.],\n",
       "         ...,\n",
       "         [111., 104.,  85.],\n",
       "         [101.,  97.,  70.],\n",
       "         [101.,  96.,  67.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 23.,  22.,  17.],\n",
       "         [ 21.,  20.,  15.],\n",
       "         [ 24.,  23.,  19.],\n",
       "         ...,\n",
       "         [ 94.,  88.,  88.],\n",
       "         [ 81.,  96.,  91.],\n",
       "         [ 76.,  99.,  83.]],\n",
       "\n",
       "        [[ 28.,  24.,  21.],\n",
       "         [ 20.,  21.,  13.],\n",
       "         [ 25.,  26.,  21.],\n",
       "         ...,\n",
       "         [ 84.,  89.,  85.],\n",
       "         [ 91.,  99.,  86.],\n",
       "         [100., 106., 118.]],\n",
       "\n",
       "        [[ 18.,  15.,  10.],\n",
       "         [ 24.,  25.,  17.],\n",
       "         [ 22.,  24.,  19.],\n",
       "         ...,\n",
       "         [ 91.,  98.,  90.],\n",
       "         [ 83.,  96.,  86.],\n",
       "         [ 83.,  99.,  98.]]]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7321240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train, x_img_test = x_img_train / 255.0, x_img_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08057125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.4392157 , 0.43137255, 0.43529412],\n",
       "         [0.47843137, 0.47058824, 0.4745098 ],\n",
       "         [0.43529412, 0.42745098, 0.43137255],\n",
       "         ...,\n",
       "         [0.8627451 , 0.8627451 , 0.8627451 ],\n",
       "         [0.8745098 , 0.8745098 , 0.88235295],\n",
       "         [0.8745098 , 0.8745098 , 0.88235295]],\n",
       "\n",
       "        [[0.72156864, 0.7137255 , 0.7176471 ],\n",
       "         [0.77254903, 0.7647059 , 0.76862746],\n",
       "         [0.80784315, 0.8       , 0.8039216 ],\n",
       "         ...,\n",
       "         [0.8666667 , 0.8666667 , 0.8666667 ],\n",
       "         [0.8745098 , 0.8745098 , 0.88235295],\n",
       "         [0.8745098 , 0.8745098 , 0.88235295]],\n",
       "\n",
       "        [[0.75686276, 0.7490196 , 0.7529412 ],\n",
       "         [0.74509805, 0.7372549 , 0.7411765 ],\n",
       "         [0.6901961 , 0.68235296, 0.6862745 ],\n",
       "         ...,\n",
       "         [0.90588236, 0.90588236, 0.90588236],\n",
       "         [0.8745098 , 0.8745098 , 0.88235295],\n",
       "         [0.8745098 , 0.8745098 , 0.88235295]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.03921569, 0.03921569, 0.03921569],\n",
       "         [0.06666667, 0.06666667, 0.06666667],\n",
       "         [0.5254902 , 0.5254902 , 0.5254902 ],\n",
       "         ...,\n",
       "         [0.627451  , 0.8039216 , 0.6745098 ],\n",
       "         [0.5803922 , 0.7411765 , 0.60784316],\n",
       "         [0.7921569 , 0.9019608 , 0.8117647 ]],\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.76862746, 0.8784314 , 0.78039217],\n",
       "         [0.4627451 , 0.60784316, 0.4862745 ],\n",
       "         [0.84313726, 0.9764706 , 0.8784314 ]],\n",
       "\n",
       "        [[0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.84705883, 0.85490197, 0.8352941 ],\n",
       "         [0.827451  , 0.8980392 , 0.8509804 ],\n",
       "         [0.62352943, 0.73333335, 0.6745098 ]]],\n",
       "\n",
       "\n",
       "       [[[0.1764706 , 0.18039216, 0.16078432],\n",
       "         [0.8117647 , 0.8117647 , 0.8039216 ],\n",
       "         [0.21568628, 0.21960784, 0.19607843],\n",
       "         ...,\n",
       "         [0.59607846, 0.5921569 , 0.6117647 ],\n",
       "         [0.69803923, 0.69803923, 0.69803923],\n",
       "         [0.7490196 , 0.7490196 , 0.7490196 ]],\n",
       "\n",
       "        [[0.12941177, 0.13333334, 0.11372549],\n",
       "         [0.8156863 , 0.8156863 , 0.80784315],\n",
       "         [0.4392157 , 0.44313726, 0.41960785],\n",
       "         ...,\n",
       "         [0.6784314 , 0.6784314 , 0.6784314 ],\n",
       "         [0.7647059 , 0.7647059 , 0.7647059 ],\n",
       "         [0.7294118 , 0.7294118 , 0.7294118 ]],\n",
       "\n",
       "        [[0.7490196 , 0.7490196 , 0.7411765 ],\n",
       "         [0.5529412 , 0.5568628 , 0.53333336],\n",
       "         [0.22745098, 0.23529412, 0.18431373],\n",
       "         ...,\n",
       "         [0.7529412 , 0.7529412 , 0.7529412 ],\n",
       "         [0.7411765 , 0.7411765 , 0.7411765 ],\n",
       "         [0.7019608 , 0.7019608 , 0.7019608 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0627451 , 0.05882353, 0.23137255],\n",
       "         [0.3019608 , 0.3019608 , 0.34901962],\n",
       "         [0.09411765, 0.09803922, 0.21568628],\n",
       "         ...,\n",
       "         [0.11764706, 0.11372549, 0.23921569],\n",
       "         [0.18431373, 0.19215687, 0.2901961 ],\n",
       "         [0.1882353 , 0.1764706 , 0.28235295]],\n",
       "\n",
       "        [[0.05490196, 0.04705882, 0.23137255],\n",
       "         [0.03529412, 0.03137255, 0.20392157],\n",
       "         [0.03921569, 0.03137255, 0.22352941],\n",
       "         ...,\n",
       "         [0.08235294, 0.08235294, 0.22352941],\n",
       "         [0.13725491, 0.14509805, 0.24313726],\n",
       "         [0.09019608, 0.08627451, 0.24313726]],\n",
       "\n",
       "        [[0.03137255, 0.02352941, 0.21568628],\n",
       "         [0.03529412, 0.02745098, 0.22352941],\n",
       "         [0.03529412, 0.02745098, 0.21960784],\n",
       "         ...,\n",
       "         [0.02745098, 0.02745098, 0.22352941],\n",
       "         [0.02745098, 0.01960784, 0.21568628],\n",
       "         [0.03137255, 0.02352941, 0.21568628]]],\n",
       "\n",
       "\n",
       "       [[[0.72156864, 0.8627451 , 0.8627451 ],\n",
       "         [0.7764706 , 0.8980392 , 0.8745098 ],\n",
       "         [0.64705884, 0.8       , 0.79607844],\n",
       "         ...,\n",
       "         [0.16862746, 0.30980393, 0.3019608 ],\n",
       "         [0.16470589, 0.23137255, 0.20784314],\n",
       "         [0.14117648, 0.22745098, 0.18039216]],\n",
       "\n",
       "        [[0.8627451 , 0.92941177, 0.8901961 ],\n",
       "         [0.92941177, 0.9529412 , 0.9137255 ],\n",
       "         [0.8745098 , 0.9529412 , 0.9098039 ],\n",
       "         ...,\n",
       "         [0.24313726, 0.3764706 , 0.32156864],\n",
       "         [0.14509805, 0.21176471, 0.1882353 ],\n",
       "         [0.14117648, 0.22745098, 0.1764706 ]],\n",
       "\n",
       "        [[0.89411765, 0.9372549 , 0.90588236],\n",
       "         [0.91764706, 0.9372549 , 0.9137255 ],\n",
       "         [0.89411765, 0.93333334, 0.8980392 ],\n",
       "         ...,\n",
       "         [0.2784314 , 0.4117647 , 0.34509805],\n",
       "         [0.16470589, 0.23137255, 0.19215687],\n",
       "         [0.14509805, 0.23137255, 0.18431373]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.19607843, 0.21568628, 0.2       ],\n",
       "         [0.15686275, 0.18039216, 0.18039216],\n",
       "         [0.14901961, 0.18039216, 0.19215687],\n",
       "         ...,\n",
       "         [0.10980392, 0.14901961, 0.10588235],\n",
       "         [0.15686275, 0.25490198, 0.23137255],\n",
       "         [0.07450981, 0.15294118, 0.11764706]],\n",
       "\n",
       "        [[0.21176471, 0.21960784, 0.20784314],\n",
       "         [0.15294118, 0.1764706 , 0.16862746],\n",
       "         [0.14509805, 0.1764706 , 0.18431373],\n",
       "         ...,\n",
       "         [0.08627451, 0.15294118, 0.12156863],\n",
       "         [0.1882353 , 0.2901961 , 0.2784314 ],\n",
       "         [0.13333334, 0.19607843, 0.18431373]],\n",
       "\n",
       "        [[0.2       , 0.20784314, 0.19607843],\n",
       "         [0.15686275, 0.18039216, 0.18039216],\n",
       "         [0.14901961, 0.18431373, 0.17254902],\n",
       "         ...,\n",
       "         [0.12941177, 0.20392157, 0.18039216],\n",
       "         [0.12156863, 0.2       , 0.19607843],\n",
       "         [0.09411765, 0.14117648, 0.14117648]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.4392157 , 0.4117647 , 0.4392157 ],\n",
       "         [0.43529412, 0.4117647 , 0.42745098],\n",
       "         [0.43529412, 0.4       , 0.40392157],\n",
       "         ...,\n",
       "         [0.58431375, 0.5254902 , 0.4509804 ],\n",
       "         [0.4862745 , 0.4392157 , 0.3529412 ],\n",
       "         [0.54509807, 0.48235294, 0.42352942]],\n",
       "\n",
       "        [[0.4627451 , 0.42745098, 0.44705883],\n",
       "         [0.45490196, 0.41960785, 0.43137255],\n",
       "         [0.44705883, 0.40784314, 0.40392157],\n",
       "         ...,\n",
       "         [0.5529412 , 0.50980395, 0.42352942],\n",
       "         [0.654902  , 0.6117647 , 0.5019608 ],\n",
       "         [0.7294118 , 0.6509804 , 0.5568628 ]],\n",
       "\n",
       "        [[0.49411765, 0.45882353, 0.47058824],\n",
       "         [0.49019608, 0.44705883, 0.4627451 ],\n",
       "         [0.49803922, 0.45882353, 0.4509804 ],\n",
       "         ...,\n",
       "         [0.21960784, 0.20392157, 0.05490196],\n",
       "         [0.19607843, 0.19607843, 0.05490196],\n",
       "         [0.1882353 , 0.1764706 , 0.04705882]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.25882354, 0.21568628, 0.2       ],\n",
       "         [0.25882354, 0.21568628, 0.2       ],\n",
       "         [0.26666668, 0.22352941, 0.20784314],\n",
       "         ...,\n",
       "         [0.34117648, 0.26666668, 0.24313726],\n",
       "         [0.34509805, 0.27058825, 0.24705882],\n",
       "         [0.32941177, 0.25490198, 0.23137255]],\n",
       "\n",
       "        [[0.2509804 , 0.20784314, 0.19215687],\n",
       "         [0.25490198, 0.21176471, 0.19607843],\n",
       "         [0.25490198, 0.21176471, 0.19607843],\n",
       "         ...,\n",
       "         [0.32941177, 0.2627451 , 0.23529412],\n",
       "         [0.3254902 , 0.25882354, 0.23137255],\n",
       "         [0.3254902 , 0.25882354, 0.23137255]],\n",
       "\n",
       "        [[0.24705882, 0.20392157, 0.1882353 ],\n",
       "         [0.25490198, 0.21176471, 0.19607843],\n",
       "         [0.25490198, 0.21176471, 0.19607843],\n",
       "         ...,\n",
       "         [0.31764707, 0.2509804 , 0.22352941],\n",
       "         [0.3137255 , 0.24705882, 0.21960784],\n",
       "         [0.3137255 , 0.24705882, 0.21960784]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         ...,\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314]],\n",
       "\n",
       "        [[1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         ...,\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314]],\n",
       "\n",
       "        [[1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         ...,\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         ...,\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314]],\n",
       "\n",
       "        [[1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         ...,\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314]],\n",
       "\n",
       "        [[1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         ...,\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.827451  , 0.00784314],\n",
       "         [1.        , 0.8235294 , 0.01176471]]],\n",
       "\n",
       "\n",
       "       [[[0.16470589, 0.10980392, 0.05882353],\n",
       "         [0.21568628, 0.15686275, 0.07450981],\n",
       "         [0.20392157, 0.14117648, 0.08235294],\n",
       "         ...,\n",
       "         [0.42745098, 0.4       , 0.36078432],\n",
       "         [0.41960785, 0.4       , 0.28235295],\n",
       "         [0.37254903, 0.34509805, 0.27450982]],\n",
       "\n",
       "        [[0.1764706 , 0.1254902 , 0.0627451 ],\n",
       "         [0.1764706 , 0.11764706, 0.03529412],\n",
       "         [0.23529412, 0.1764706 , 0.10196079],\n",
       "         ...,\n",
       "         [0.41568628, 0.39215687, 0.3372549 ],\n",
       "         [0.41960785, 0.3764706 , 0.2901961 ],\n",
       "         [0.39215687, 0.34509805, 0.2901961 ]],\n",
       "\n",
       "        [[0.18431373, 0.12156863, 0.0627451 ],\n",
       "         [0.20784314, 0.14901961, 0.05882353],\n",
       "         [0.19607843, 0.13725491, 0.05490196],\n",
       "         ...,\n",
       "         [0.43529412, 0.40784314, 0.33333334],\n",
       "         [0.39607844, 0.38039216, 0.27450982],\n",
       "         [0.39607844, 0.3764706 , 0.2627451 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.09019608, 0.08627451, 0.06666667],\n",
       "         [0.08235294, 0.07843138, 0.05882353],\n",
       "         [0.09411765, 0.09019608, 0.07450981],\n",
       "         ...,\n",
       "         [0.36862746, 0.34509805, 0.34509805],\n",
       "         [0.31764707, 0.3764706 , 0.35686275],\n",
       "         [0.29803923, 0.3882353 , 0.3254902 ]],\n",
       "\n",
       "        [[0.10980392, 0.09411765, 0.08235294],\n",
       "         [0.07843138, 0.08235294, 0.05098039],\n",
       "         [0.09803922, 0.10196079, 0.08235294],\n",
       "         ...,\n",
       "         [0.32941177, 0.34901962, 0.33333334],\n",
       "         [0.35686275, 0.3882353 , 0.3372549 ],\n",
       "         [0.39215687, 0.41568628, 0.4627451 ]],\n",
       "\n",
       "        [[0.07058824, 0.05882353, 0.03921569],\n",
       "         [0.09411765, 0.09803922, 0.06666667],\n",
       "         [0.08627451, 0.09411765, 0.07450981],\n",
       "         ...,\n",
       "         [0.35686275, 0.38431373, 0.3529412 ],\n",
       "         [0.3254902 , 0.3764706 , 0.3372549 ],\n",
       "         [0.3254902 , 0.3882353 , 0.38431373]]]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e224435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ResNet = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "for layer in ResNet.layers:\n",
    "    layer.trainable = False\n",
    "ResNet = Model(inputs=ResNet.inputs, outputs=ResNet.layers[-2].output)\n",
    "ResNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63a00da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ResNet.predict(x_img_train)\n",
    "features_test = ResNet.predict(x_img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65c73749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6794, 2048)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2eddce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = tf.keras.Input(shape=(2048,), name='img_input')\n",
    "title_input = tf.keras.Input(shape=(768,), name='title_input')\n",
    "des_input = tf.keras.Input(shape=(768,), name='des_input')\n",
    "\n",
    "img_feat = tf.keras.layers.Dense(768,)(img_input)\n",
    "\n",
    "x = tf.keras.layers.Concatenate(axis=1)([img_input,title_input,img_feat])\n",
    "\n",
    "name_pred = tf.keras.layers.Dense(y_one_hot.shape[1],name=\"name\")(x)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[img_input, title_input, des_input],\n",
    "    outputs=[name_pred],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a52f4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[\n",
    "        tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    ],\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b67b5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/10\n",
      "340/340 [==============================] - 7s 20ms/step - loss: 6.2079 - accuracy: 0.0967\n",
      "Epoch 2/10\n",
      "340/340 [==============================] - 7s 20ms/step - loss: 2.7588 - accuracy: 0.4787\n",
      "Epoch 3/10\n",
      "340/340 [==============================] - 7s 20ms/step - loss: 1.6038 - accuracy: 0.6874\n",
      "Epoch 4/10\n",
      "340/340 [==============================] - 7s 20ms/step - loss: 1.1514 - accuracy: 0.7648\n",
      "Epoch 5/10\n",
      "340/340 [==============================] - 7s 20ms/step - loss: 0.8957 - accuracy: 0.8131\n",
      "Epoch 6/10\n",
      "340/340 [==============================] - 7s 20ms/step - loss: 0.7565 - accuracy: 0.8354\n",
      "Epoch 7/10\n",
      "340/340 [==============================] - 7s 21ms/step - loss: 0.6367 - accuracy: 0.8628\n",
      "Epoch 8/10\n",
      "340/340 [==============================] - 7s 20ms/step - loss: 0.5766 - accuracy: 0.8689\n",
      "Epoch 9/10\n",
      "340/340 [==============================] - 7s 20ms/step - loss: 0.5467 - accuracy: 0.8775\n",
      "Epoch 10/10\n",
      "340/340 [==============================] - 7s 20ms/step - loss: 0.4917 - accuracy: 0.8878\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    [features,x_title_train,x_des_train],\n",
    "    y_one_hot_train,\n",
    "    batch_size=20,\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a96d8c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.8534\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(\n",
    "    [features_test,x_title_test,x_des_test], \n",
    "    y_one_hot_test, \n",
    "    batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6f08a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.13      1.00      0.23         3\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       1.00      0.25      0.40         4\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.75      1.00      0.86         3\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       1.00      1.00      1.00         2\n",
      "          17       0.50      1.00      0.67         1\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       1.00      1.00      1.00         4\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       1.00      1.00      1.00         5\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.25      1.00      0.40         1\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.50      1.00      0.67         1\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       0.40      1.00      0.57         2\n",
      "          40       0.00      0.00      0.00         2\n",
      "          41       1.00      1.00      1.00         2\n",
      "          42       1.00      1.00      1.00         1\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       1.00      1.00      1.00         4\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       1.00      1.00      1.00         1\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         1\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       1.00      1.00      1.00         1\n",
      "          54       1.00      1.00      1.00         1\n",
      "          55       0.67      1.00      0.80         2\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       1.00      1.00      1.00         1\n",
      "          58       1.00      1.00      1.00         1\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         1\n",
      "          61       1.00      1.00      1.00         1\n",
      "          62       1.00      1.00      1.00         3\n",
      "          63       0.80      1.00      0.89         4\n",
      "          64       1.00      1.00      1.00         1\n",
      "          65       1.00      1.00      1.00         3\n",
      "          66       1.00      1.00      1.00         1\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00         1\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         3\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       1.00      1.00      1.00         2\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         4\n",
      "          78       1.00      1.00      1.00         1\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         1\n",
      "          82       1.00      1.00      1.00         2\n",
      "          84       1.00      0.50      0.67         2\n",
      "          85       1.00      1.00      1.00         1\n",
      "          86       1.00      1.00      1.00         2\n",
      "          87       0.00      0.00      0.00         1\n",
      "          89       1.00      1.00      1.00         2\n",
      "          91       1.00      1.00      1.00         2\n",
      "          94       1.00      1.00      1.00         3\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       1.00      1.00      1.00         5\n",
      "          97       1.00      1.00      1.00         1\n",
      "          99       0.33      1.00      0.50         1\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       1.00      1.00      1.00         1\n",
      "         102       1.00      1.00      1.00         1\n",
      "         103       1.00      1.00      1.00         3\n",
      "         104       1.00      1.00      1.00         3\n",
      "         105       1.00      1.00      1.00         1\n",
      "         107       1.00      1.00      1.00         3\n",
      "         108       1.00      1.00      1.00         2\n",
      "         109       1.00      1.00      1.00         1\n",
      "         110       1.00      1.00      1.00         1\n",
      "         111       1.00      1.00      1.00         3\n",
      "         112       1.00      0.50      0.67         2\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       1.00      1.00      1.00         1\n",
      "         115       1.00      0.50      0.67         2\n",
      "         116       1.00      1.00      1.00         1\n",
      "         117       1.00      1.00      1.00         3\n",
      "         118       1.00      1.00      1.00         2\n",
      "         119       1.00      1.00      1.00         1\n",
      "         120       1.00      1.00      1.00        13\n",
      "         122       1.00      1.00      1.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       1.00      1.00      1.00         3\n",
      "         125       0.00      0.00      0.00         1\n",
      "         126       1.00      1.00      1.00         1\n",
      "         127       1.00      0.75      0.86         4\n",
      "         128       0.00      0.00      0.00         1\n",
      "         129       1.00      1.00      1.00         2\n",
      "         130       1.00      1.00      1.00         2\n",
      "         131       1.00      1.00      1.00         2\n",
      "         132       1.00      1.00      1.00         3\n",
      "         133       1.00      1.00      1.00         2\n",
      "         135       1.00      1.00      1.00         2\n",
      "         136       1.00      1.00      1.00         2\n",
      "         137       1.00      1.00      1.00         3\n",
      "         139       1.00      0.50      0.67         2\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       0.00      0.00      0.00         1\n",
      "         143       0.50      1.00      0.67         1\n",
      "         144       1.00      1.00      1.00         2\n",
      "         145       1.00      1.00      1.00         1\n",
      "         146       1.00      1.00      1.00         3\n",
      "         147       1.00      1.00      1.00         1\n",
      "         148       1.00      1.00      1.00         1\n",
      "         149       0.00      0.00      0.00         2\n",
      "         150       0.00      0.00      0.00         1\n",
      "         151       1.00      1.00      1.00         2\n",
      "         152       1.00      1.00      1.00         2\n",
      "         153       1.00      1.00      1.00         1\n",
      "         155       1.00      1.00      1.00         3\n",
      "         156       1.00      1.00      1.00         1\n",
      "         157       1.00      1.00      1.00         1\n",
      "         158       1.00      1.00      1.00         4\n",
      "         159       1.00      1.00      1.00         2\n",
      "         160       1.00      1.00      1.00         3\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       1.00      1.00      1.00         4\n",
      "         163       1.00      1.00      1.00         2\n",
      "         164       1.00      1.00      1.00         2\n",
      "         166       1.00      0.67      0.80         3\n",
      "         167       1.00      1.00      1.00         1\n",
      "         168       0.00      0.00      0.00         2\n",
      "         170       1.00      1.00      1.00         2\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.50      1.00      0.67         1\n",
      "         173       1.00      1.00      1.00         1\n",
      "         174       1.00      1.00      1.00         1\n",
      "         175       1.00      1.00      1.00         2\n",
      "         176       1.00      1.00      1.00         3\n",
      "         177       1.00      1.00      1.00         2\n",
      "         178       1.00      1.00      1.00         2\n",
      "         180       1.00      1.00      1.00         1\n",
      "         181       1.00      1.00      1.00         2\n",
      "         182       1.00      0.33      0.50         3\n",
      "         183       1.00      1.00      1.00         1\n",
      "         184       0.43      1.00      0.60         3\n",
      "         185       1.00      1.00      1.00         1\n",
      "         186       1.00      1.00      1.00         2\n",
      "         187       1.00      1.00      1.00         1\n",
      "         188       1.00      1.00      1.00         1\n",
      "         189       1.00      1.00      1.00         1\n",
      "         190       1.00      1.00      1.00         3\n",
      "         191       1.00      1.00      1.00         2\n",
      "         192       1.00      1.00      1.00         1\n",
      "         194       1.00      1.00      1.00         2\n",
      "         195       1.00      1.00      1.00         2\n",
      "         196       1.00      1.00      1.00         2\n",
      "         197       1.00      1.00      1.00         3\n",
      "         199       1.00      1.00      1.00         3\n",
      "         200       1.00      1.00      1.00         2\n",
      "         202       1.00      1.00      1.00         1\n",
      "         203       1.00      1.00      1.00         2\n",
      "         204       1.00      1.00      1.00         2\n",
      "         207       1.00      1.00      1.00         1\n",
      "         208       1.00      1.00      1.00         2\n",
      "         209       1.00      1.00      1.00         2\n",
      "         210       1.00      1.00      1.00         3\n",
      "         211       1.00      1.00      1.00         2\n",
      "         212       1.00      1.00      1.00         2\n",
      "         213       1.00      1.00      1.00         3\n",
      "         214       1.00      1.00      1.00         3\n",
      "         215       0.50      1.00      0.67         2\n",
      "         217       1.00      1.00      1.00         2\n",
      "         218       0.00      0.00      0.00         2\n",
      "         219       1.00      1.00      1.00         1\n",
      "         220       1.00      1.00      1.00         1\n",
      "         221       1.00      1.00      1.00         1\n",
      "         222       1.00      1.00      1.00         1\n",
      "         223       1.00      1.00      1.00         2\n",
      "         224       1.00      1.00      1.00         1\n",
      "         225       1.00      1.00      1.00         4\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       1.00      1.00      1.00         1\n",
      "         228       1.00      1.00      1.00         2\n",
      "         229       1.00      1.00      1.00         3\n",
      "         230       0.00      0.00      0.00         1\n",
      "         231       0.00      0.00      0.00         3\n",
      "         232       1.00      1.00      1.00         1\n",
      "         233       1.00      1.00      1.00         1\n",
      "         234       1.00      1.00      1.00         1\n",
      "         235       1.00      1.00      1.00         2\n",
      "         236       1.00      1.00      1.00         3\n",
      "         237       0.67      1.00      0.80         2\n",
      "         238       1.00      1.00      1.00         1\n",
      "         239       1.00      1.00      1.00         1\n",
      "         240       1.00      1.00      1.00         4\n",
      "         241       1.00      1.00      1.00         1\n",
      "         242       1.00      1.00      1.00         3\n",
      "         245       1.00      1.00      1.00         1\n",
      "         246       1.00      1.00      1.00         2\n",
      "         247       1.00      1.00      1.00         2\n",
      "         248       1.00      1.00      1.00         3\n",
      "         249       1.00      1.00      1.00         2\n",
      "         250       1.00      0.75      0.86         4\n",
      "         251       1.00      1.00      1.00         2\n",
      "         253       1.00      1.00      1.00         3\n",
      "         254       1.00      1.00      1.00         1\n",
      "         255       1.00      1.00      1.00         2\n",
      "         256       1.00      1.00      1.00         3\n",
      "         257       1.00      1.00      1.00         3\n",
      "         258       1.00      1.00      1.00         1\n",
      "         259       1.00      1.00      1.00         2\n",
      "         260       1.00      0.40      0.57         5\n",
      "         261       1.00      1.00      1.00         3\n",
      "         262       1.00      1.00      1.00         3\n",
      "         263       1.00      1.00      1.00         1\n",
      "         264       1.00      1.00      1.00         3\n",
      "         265       1.00      1.00      1.00         1\n",
      "         266       1.00      1.00      1.00         1\n",
      "         267       1.00      1.00      1.00         1\n",
      "         268       1.00      1.00      1.00         1\n",
      "         269       1.00      1.00      1.00         1\n",
      "         270       1.00      1.00      1.00         1\n",
      "         271       1.00      1.00      1.00         1\n",
      "         272       1.00      1.00      1.00         2\n",
      "         273       1.00      1.00      1.00         5\n",
      "         274       1.00      1.00      1.00         1\n",
      "         275       1.00      1.00      1.00         1\n",
      "         277       1.00      1.00      1.00         1\n",
      "         278       1.00      1.00      1.00         1\n",
      "         279       1.00      1.00      1.00         2\n",
      "         280       1.00      1.00      1.00         2\n",
      "         282       1.00      1.00      1.00         1\n",
      "         283       1.00      1.00      1.00         1\n",
      "         284       1.00      1.00      1.00         3\n",
      "         285       0.17      0.33      0.22         3\n",
      "         286       1.00      1.00      1.00         1\n",
      "         287       0.17      1.00      0.29         2\n",
      "         288       0.00      0.00      0.00         1\n",
      "         289       1.00      1.00      1.00         4\n",
      "         290       0.80      1.00      0.89         4\n",
      "         292       1.00      1.00      1.00         3\n",
      "         293       1.00      1.00      1.00         1\n",
      "         294       1.00      1.00      1.00         2\n",
      "         295       1.00      1.00      1.00         3\n",
      "         296       1.00      1.00      1.00         1\n",
      "         298       1.00      1.00      1.00         3\n",
      "         299       1.00      1.00      1.00         1\n",
      "         302       1.00      1.00      1.00         1\n",
      "         303       1.00      1.00      1.00         1\n",
      "         304       0.00      0.00      0.00         1\n",
      "         305       0.00      0.00      0.00         2\n",
      "         307       1.00      1.00      1.00         1\n",
      "         308       1.00      0.50      0.67         2\n",
      "         309       0.75      1.00      0.86         3\n",
      "         311       1.00      1.00      1.00         1\n",
      "         312       1.00      1.00      1.00         1\n",
      "         313       1.00      1.00      1.00         1\n",
      "         314       1.00      1.00      1.00         2\n",
      "         315       1.00      1.00      1.00         2\n",
      "         316       0.67      0.67      0.67         6\n",
      "         317       0.00      0.00      0.00         5\n",
      "         318       1.00      1.00      1.00         3\n",
      "         319       1.00      1.00      1.00         3\n",
      "         320       1.00      1.00      1.00         1\n",
      "         322       1.00      1.00      1.00         2\n",
      "         323       0.67      1.00      0.80         2\n",
      "         324       0.00      0.00      0.00         4\n",
      "         325       1.00      1.00      1.00         3\n",
      "         326       1.00      1.00      1.00         3\n",
      "         327       1.00      1.00      1.00         1\n",
      "         328       1.00      1.00      1.00         2\n",
      "         329       1.00      1.00      1.00         3\n",
      "         330       1.00      1.00      1.00         2\n",
      "         331       1.00      1.00      1.00         1\n",
      "         332       1.00      1.00      1.00         1\n",
      "         333       1.00      1.00      1.00         3\n",
      "         334       1.00      1.00      1.00         2\n",
      "         335       1.00      1.00      1.00         1\n",
      "         336       0.00      0.00      0.00         1\n",
      "         337       1.00      1.00      1.00         2\n",
      "         338       1.00      0.75      0.86         4\n",
      "         339       1.00      1.00      1.00         1\n",
      "         340       1.00      1.00      1.00         2\n",
      "         341       1.00      1.00      1.00         3\n",
      "         342       1.00      1.00      1.00         2\n",
      "         343       1.00      1.00      1.00         1\n",
      "         344       1.00      1.00      1.00         1\n",
      "         345       1.00      1.00      1.00         4\n",
      "         346       0.00      0.00      0.00         1\n",
      "         347       1.00      1.00      1.00         1\n",
      "         348       1.00      1.00      1.00         1\n",
      "         349       1.00      1.00      1.00         4\n",
      "         350       0.71      1.00      0.83         5\n",
      "         351       0.00      0.00      0.00         0\n",
      "         352       1.00      1.00      1.00         1\n",
      "         353       1.00      1.00      1.00         2\n",
      "         354       1.00      1.00      1.00         1\n",
      "         355       0.00      0.00      0.00         0\n",
      "         356       0.00      0.00      0.00         1\n",
      "         357       1.00      1.00      1.00         3\n",
      "         358       1.00      1.00      1.00         4\n",
      "         359       1.00      1.00      1.00         3\n",
      "         360       0.00      0.00      0.00         1\n",
      "         361       0.00      0.00      0.00         2\n",
      "         362       1.00      1.00      1.00         2\n",
      "         363       0.00      0.00      0.00         0\n",
      "         364       1.00      1.00      1.00         1\n",
      "         365       1.00      1.00      1.00         1\n",
      "         367       1.00      1.00      1.00         1\n",
      "         368       0.00      0.00      0.00         3\n",
      "         372       1.00      1.00      1.00         1\n",
      "         375       1.00      1.00      1.00         2\n",
      "         376       1.00      1.00      1.00         3\n",
      "         377       1.00      1.00      1.00         2\n",
      "         378       1.00      1.00      1.00         3\n",
      "         379       1.00      1.00      1.00         5\n",
      "         380       1.00      1.00      1.00         5\n",
      "         381       1.00      1.00      1.00         1\n",
      "         382       0.00      0.00      0.00         0\n",
      "         383       1.00      1.00      1.00         3\n",
      "         385       1.00      1.00      1.00         4\n",
      "         386       1.00      1.00      1.00         1\n",
      "         387       1.00      1.00      1.00         3\n",
      "         388       1.00      1.00      1.00         2\n",
      "         389       0.00      0.00      0.00         0\n",
      "         390       1.00      1.00      1.00         5\n",
      "         391       1.00      1.00      1.00         3\n",
      "         392       1.00      1.00      1.00         2\n",
      "         394       1.00      1.00      1.00         4\n",
      "         395       1.00      1.00      1.00         2\n",
      "         396       1.00      1.00      1.00         3\n",
      "         397       1.00      1.00      1.00         1\n",
      "         398       1.00      1.00      1.00         4\n",
      "         399       0.50      1.00      0.67         1\n",
      "         400       1.00      1.00      1.00         2\n",
      "         401       1.00      1.00      1.00         1\n",
      "         402       1.00      1.00      1.00         2\n",
      "         404       1.00      1.00      1.00         1\n",
      "         406       0.00      0.00      0.00         3\n",
      "         407       0.00      0.00      0.00         0\n",
      "         408       1.00      1.00      1.00         4\n",
      "         409       1.00      1.00      1.00         2\n",
      "         410       1.00      0.50      0.67         2\n",
      "         411       1.00      1.00      1.00         1\n",
      "         413       1.00      1.00      1.00         1\n",
      "         414       1.00      1.00      1.00         2\n",
      "         415       1.00      1.00      1.00         2\n",
      "         416       1.00      1.00      1.00         7\n",
      "         417       1.00      1.00      1.00         2\n",
      "         418       0.17      1.00      0.29         1\n",
      "         419       1.00      1.00      1.00         1\n",
      "         420       1.00      0.50      0.67         2\n",
      "         421       1.00      1.00      1.00         1\n",
      "         422       1.00      1.00      1.00         1\n",
      "         423       1.00      1.00      1.00         2\n",
      "         424       1.00      1.00      1.00         1\n",
      "         425       1.00      1.00      1.00         1\n",
      "         426       1.00      1.00      1.00         2\n",
      "         427       1.00      1.00      1.00         2\n",
      "         428       1.00      0.50      0.67         6\n",
      "         429       1.00      1.00      1.00         4\n",
      "         431       1.00      1.00      1.00         5\n",
      "         432       0.00      0.00      0.00         1\n",
      "         433       1.00      1.00      1.00         2\n",
      "         434       1.00      1.00      1.00         1\n",
      "         435       1.00      1.00      1.00         4\n",
      "         437       1.00      1.00      1.00         1\n",
      "         438       1.00      1.00      1.00         2\n",
      "         439       1.00      1.00      1.00         3\n",
      "         440       1.00      1.00      1.00         3\n",
      "         441       1.00      1.00      1.00         1\n",
      "         442       1.00      1.00      1.00         3\n",
      "         443       1.00      1.00      1.00         2\n",
      "         444       1.00      1.00      1.00         1\n",
      "         445       1.00      1.00      1.00         2\n",
      "         446       1.00      1.00      1.00         1\n",
      "         448       1.00      1.00      1.00         4\n",
      "         449       0.00      0.00      0.00         3\n",
      "         451       1.00      1.00      1.00         2\n",
      "         454       1.00      1.00      1.00         4\n",
      "         455       1.00      1.00      1.00         2\n",
      "         456       1.00      1.00      1.00         1\n",
      "         457       1.00      1.00      1.00         4\n",
      "         458       1.00      1.00      1.00         2\n",
      "         459       1.00      1.00      1.00         1\n",
      "         460       1.00      1.00      1.00         4\n",
      "         461       1.00      1.00      1.00         2\n",
      "         462       1.00      1.00      1.00         1\n",
      "         463       1.00      1.00      1.00         2\n",
      "         464       0.00      0.00      0.00         2\n",
      "         465       1.00      1.00      1.00         1\n",
      "         466       1.00      1.00      1.00         1\n",
      "         467       1.00      1.00      1.00         2\n",
      "         470       1.00      1.00      1.00         1\n",
      "         471       1.00      1.00      1.00         1\n",
      "         472       1.00      1.00      1.00         2\n",
      "         473       1.00      1.00      1.00         1\n",
      "         474       0.00      0.00      0.00         1\n",
      "         475       1.00      1.00      1.00         1\n",
      "         476       1.00      1.00      1.00         3\n",
      "         478       1.00      1.00      1.00         2\n",
      "         479       1.00      1.00      1.00         2\n",
      "         480       1.00      1.00      1.00         1\n",
      "         481       1.00      1.00      1.00         5\n",
      "         482       1.00      1.00      1.00         1\n",
      "         483       1.00      0.50      0.67         4\n",
      "         484       1.00      1.00      1.00         5\n",
      "         486       1.00      1.00      1.00         1\n",
      "         488       1.00      1.00      1.00         1\n",
      "         490       1.00      1.00      1.00         1\n",
      "         491       1.00      1.00      1.00         1\n",
      "         492       1.00      1.00      1.00         1\n",
      "         493       1.00      1.00      1.00         3\n",
      "         494       1.00      1.00      1.00         2\n",
      "         495       1.00      1.00      1.00         1\n",
      "         497       0.00      0.00      0.00         4\n",
      "         498       1.00      1.00      1.00         1\n",
      "         499       1.00      1.00      1.00         3\n",
      "         501       1.00      1.00      1.00         3\n",
      "         502       1.00      0.75      0.86         4\n",
      "         503       1.00      1.00      1.00         3\n",
      "         504       1.00      1.00      1.00         2\n",
      "         505       1.00      1.00      1.00         2\n",
      "         506       0.00      0.00      0.00         3\n",
      "         508       1.00      1.00      1.00         2\n",
      "         509       1.00      1.00      1.00         1\n",
      "         510       1.00      1.00      1.00         2\n",
      "         511       1.00      1.00      1.00         1\n",
      "         512       0.00      0.00      0.00         2\n",
      "         513       1.00      1.00      1.00         2\n",
      "         515       1.00      1.00      1.00         1\n",
      "         516       1.00      0.75      0.86         4\n",
      "         517       1.00      1.00      1.00         1\n",
      "         519       1.00      1.00      1.00         2\n",
      "         520       0.00      0.00      0.00         4\n",
      "         521       1.00      1.00      1.00         2\n",
      "         523       1.00      1.00      1.00         2\n",
      "         524       1.00      1.00      1.00         2\n",
      "         525       1.00      1.00      1.00         2\n",
      "         526       1.00      1.00      1.00         2\n",
      "         527       1.00      1.00      1.00         1\n",
      "         528       1.00      1.00      1.00         2\n",
      "         529       0.00      0.00      0.00         1\n",
      "         530       0.75      1.00      0.86         3\n",
      "         531       1.00      1.00      1.00         1\n",
      "         532       1.00      1.00      1.00         2\n",
      "         533       1.00      1.00      1.00         2\n",
      "         534       1.00      1.00      1.00         2\n",
      "         535       1.00      1.00      1.00         2\n",
      "         537       1.00      1.00      1.00         1\n",
      "         538       0.00      0.00      0.00         2\n",
      "         539       1.00      1.00      1.00         2\n",
      "         540       1.00      1.00      1.00         2\n",
      "         541       0.07      1.00      0.14         5\n",
      "         542       1.00      1.00      1.00         1\n",
      "         543       1.00      1.00      1.00         2\n",
      "         544       1.00      1.00      1.00         3\n",
      "         546       1.00      1.00      1.00         2\n",
      "         547       1.00      1.00      1.00         1\n",
      "         548       1.00      1.00      1.00         2\n",
      "         549       1.00      1.00      1.00         1\n",
      "         550       0.00      0.00      0.00         5\n",
      "         553       1.00      1.00      1.00         3\n",
      "         554       1.00      1.00      1.00         2\n",
      "         555       1.00      1.00      1.00         1\n",
      "         556       1.00      1.00      1.00         2\n",
      "         557       1.00      1.00      1.00         1\n",
      "         558       0.00      0.00      0.00         1\n",
      "         559       1.00      1.00      1.00         2\n",
      "         560       1.00      1.00      1.00         1\n",
      "         561       1.00      1.00      1.00         3\n",
      "         562       1.00      1.00      1.00         1\n",
      "         563       1.00      1.00      1.00         1\n",
      "         566       1.00      1.00      1.00         2\n",
      "         567       1.00      1.00      1.00         3\n",
      "         568       1.00      1.00      1.00         4\n",
      "         570       0.40      1.00      0.57         2\n",
      "         571       1.00      1.00      1.00         1\n",
      "         573       1.00      1.00      1.00         1\n",
      "         574       1.00      1.00      1.00         1\n",
      "         575       1.00      1.00      1.00         1\n",
      "         576       1.00      1.00      1.00         4\n",
      "         577       1.00      1.00      1.00         1\n",
      "         578       0.00      0.00      0.00        10\n",
      "         579       1.00      1.00      1.00         2\n",
      "         580       1.00      1.00      1.00         3\n",
      "         584       1.00      1.00      1.00         3\n",
      "         585       0.00      0.00      0.00         4\n",
      "         586       1.00      1.00      1.00         1\n",
      "         587       1.00      1.00      1.00         1\n",
      "         588       1.00      1.00      1.00         2\n",
      "         590       1.00      1.00      1.00         1\n",
      "         591       1.00      1.00      1.00         2\n",
      "         592       0.67      1.00      0.80         2\n",
      "         593       1.00      1.00      1.00         1\n",
      "         594       1.00      1.00      1.00         1\n",
      "         595       1.00      1.00      1.00         2\n",
      "         596       1.00      1.00      1.00         2\n",
      "         598       1.00      1.00      1.00         2\n",
      "         599       1.00      1.00      1.00         3\n",
      "         600       1.00      1.00      1.00         4\n",
      "         601       0.00      0.00      0.00         7\n",
      "         602       1.00      1.00      1.00         1\n",
      "         603       1.00      1.00      1.00         1\n",
      "         604       1.00      1.00      1.00         2\n",
      "         605       1.00      1.00      1.00         1\n",
      "         606       1.00      1.00      1.00         1\n",
      "         607       1.00      1.00      1.00         1\n",
      "         608       0.00      0.00      0.00         1\n",
      "         609       1.00      1.00      1.00         3\n",
      "         610       1.00      1.00      1.00         3\n",
      "         611       1.00      1.00      1.00         6\n",
      "         612       0.00      0.00      0.00         0\n",
      "         613       0.00      0.00      0.00         1\n",
      "         614       1.00      1.00      1.00         2\n",
      "         615       0.50      1.00      0.67         3\n",
      "         617       1.00      1.00      1.00         2\n",
      "         618       1.00      1.00      1.00         1\n",
      "         619       1.00      1.00      1.00         3\n",
      "         621       1.00      1.00      1.00         2\n",
      "         622       1.00      1.00      1.00         1\n",
      "         624       1.00      1.00      1.00         3\n",
      "         627       1.00      1.00      1.00         1\n",
      "         628       1.00      1.00      1.00         2\n",
      "         629       1.00      1.00      1.00         2\n",
      "         630       1.00      1.00      1.00         1\n",
      "         631       1.00      1.00      1.00         3\n",
      "         632       0.00      0.00      0.00         2\n",
      "         633       1.00      1.00      1.00         1\n",
      "         634       1.00      1.00      1.00         4\n",
      "         635       1.00      1.00      1.00         3\n",
      "         638       1.00      1.00      1.00         4\n",
      "         639       1.00      1.00      1.00         2\n",
      "         640       1.00      1.00      1.00         2\n",
      "         641       1.00      1.00      1.00         2\n",
      "         642       1.00      1.00      1.00         1\n",
      "         644       1.00      1.00      1.00         3\n",
      "         646       1.00      1.00      1.00         1\n",
      "         647       1.00      1.00      1.00         5\n",
      "         648       1.00      1.00      1.00         2\n",
      "         649       1.00      1.00      1.00         2\n",
      "         650       1.00      1.00      1.00         2\n",
      "         651       1.00      1.00      1.00         1\n",
      "         652       1.00      1.00      1.00         3\n",
      "         653       1.00      1.00      1.00         1\n",
      "         654       0.75      1.00      0.86         3\n",
      "         658       1.00      1.00      1.00         2\n",
      "         660       1.00      1.00      1.00         1\n",
      "         661       0.00      0.00      0.00         1\n",
      "         662       1.00      1.00      1.00         3\n",
      "         663       1.00      1.00      1.00         1\n",
      "         665       0.25      1.00      0.40         1\n",
      "         666       1.00      1.00      1.00         1\n",
      "         668       1.00      1.00      1.00         3\n",
      "         669       1.00      1.00      1.00         1\n",
      "         670       1.00      1.00      1.00         1\n",
      "         671       1.00      1.00      1.00         1\n",
      "         672       1.00      1.00      1.00         1\n",
      "         673       1.00      1.00      1.00         2\n",
      "         674       0.00      0.00      0.00         2\n",
      "         675       1.00      1.00      1.00         3\n",
      "         677       1.00      1.00      1.00         2\n",
      "         678       0.00      0.00      0.00         0\n",
      "         679       0.25      1.00      0.40         1\n",
      "         680       0.00      0.00      0.00         1\n",
      "         681       1.00      0.33      0.50         3\n",
      "         682       1.00      0.50      0.67         2\n",
      "         683       1.00      1.00      1.00         1\n",
      "         684       1.00      1.00      1.00         1\n",
      "         685       1.00      1.00      1.00         3\n",
      "         686       1.00      1.00      1.00         3\n",
      "         687       1.00      1.00      1.00         3\n",
      "         688       0.00      0.00      0.00         5\n",
      "         689       1.00      0.33      0.50         3\n",
      "         690       1.00      1.00      1.00         2\n",
      "         691       1.00      1.00      1.00         3\n",
      "         692       1.00      1.00      1.00         3\n",
      "         693       1.00      1.00      1.00         1\n",
      "         694       1.00      1.00      1.00         2\n",
      "         695       0.00      0.00      0.00         1\n",
      "         696       1.00      1.00      1.00         3\n",
      "         697       1.00      1.00      1.00         1\n",
      "         698       1.00      1.00      1.00         1\n",
      "         699       1.00      1.00      1.00         3\n",
      "         701       1.00      1.00      1.00         2\n",
      "         702       1.00      1.00      1.00         1\n",
      "         703       1.00      1.00      1.00         2\n",
      "         704       1.00      1.00      1.00         2\n",
      "         705       1.00      1.00      1.00         2\n",
      "         707       1.00      1.00      1.00         2\n",
      "         708       0.00      0.00      0.00         4\n",
      "         710       1.00      1.00      1.00         3\n",
      "         711       1.00      1.00      1.00         3\n",
      "         712       1.00      1.00      1.00         1\n",
      "         713       1.00      1.00      1.00         2\n",
      "         714       1.00      1.00      1.00         2\n",
      "         715       1.00      1.00      1.00         2\n",
      "         718       1.00      1.00      1.00         1\n",
      "         719       1.00      1.00      1.00         1\n",
      "         720       1.00      1.00      1.00         1\n",
      "         721       0.00      0.00      0.00         2\n",
      "         722       1.00      1.00      1.00         2\n",
      "         723       1.00      1.00      1.00         1\n",
      "         724       1.00      1.00      1.00         1\n",
      "         726       1.00      1.00      1.00         1\n",
      "         727       0.00      0.00      0.00         1\n",
      "         728       1.00      1.00      1.00         3\n",
      "         729       1.00      1.00      1.00         3\n",
      "         730       1.00      1.00      1.00         3\n",
      "         731       0.00      0.00      0.00         1\n",
      "         732       0.00      0.00      0.00         1\n",
      "         733       0.67      1.00      0.80         2\n",
      "         734       1.00      1.00      1.00         3\n",
      "         735       1.00      1.00      1.00         1\n",
      "         736       1.00      1.00      1.00         1\n",
      "         738       0.00      0.00      0.00         4\n",
      "         739       0.00      0.00      0.00         1\n",
      "         740       1.00      1.00      1.00         5\n",
      "         741       1.00      1.00      1.00         2\n",
      "         742       1.00      1.00      1.00         1\n",
      "         743       1.00      1.00      1.00         2\n",
      "         744       1.00      1.00      1.00         2\n",
      "         745       1.00      1.00      1.00         1\n",
      "         746       1.00      1.00      1.00         2\n",
      "         747       1.00      1.00      1.00         3\n",
      "         748       1.00      1.00      1.00         2\n",
      "         749       1.00      0.50      0.67         4\n",
      "         750       1.00      1.00      1.00         1\n",
      "         751       1.00      1.00      1.00         1\n",
      "         752       0.22      1.00      0.36         2\n",
      "         753       0.00      0.00      0.00         5\n",
      "         754       1.00      1.00      1.00         1\n",
      "         755       1.00      1.00      1.00         2\n",
      "         756       0.00      0.00      0.00         1\n",
      "         757       1.00      1.00      1.00         4\n",
      "         758       1.00      1.00      1.00         1\n",
      "         759       1.00      1.00      1.00         1\n",
      "         760       1.00      1.00      1.00         4\n",
      "         761       0.00      0.00      0.00         2\n",
      "         762       1.00      1.00      1.00         2\n",
      "         763       1.00      1.00      1.00         3\n",
      "         764       1.00      1.00      1.00         1\n",
      "         766       1.00      1.00      1.00         1\n",
      "         768       1.00      1.00      1.00         2\n",
      "         771       1.00      1.00      1.00         3\n",
      "         772       1.00      1.00      1.00         2\n",
      "         773       0.00      0.00      0.00         1\n",
      "         774       1.00      0.50      0.67         2\n",
      "         776       1.00      1.00      1.00         4\n",
      "         778       1.00      1.00      1.00         1\n",
      "         779       1.00      1.00      1.00         1\n",
      "         780       1.00      1.00      1.00         4\n",
      "         781       1.00      0.33      0.50         3\n",
      "         782       0.00      0.00      0.00         1\n",
      "         783       1.00      1.00      1.00         2\n",
      "         784       1.00      1.00      1.00         2\n",
      "         786       1.00      1.00      1.00         2\n",
      "         787       1.00      1.00      1.00         1\n",
      "         788       1.00      0.67      0.80         3\n",
      "         789       1.00      1.00      1.00         1\n",
      "         790       1.00      1.00      1.00         2\n",
      "         791       1.00      1.00      1.00         4\n",
      "         792       1.00      0.33      0.50         3\n",
      "         793       1.00      1.00      1.00         1\n",
      "         794       0.00      0.00      0.00         3\n",
      "         795       1.00      1.00      1.00         1\n",
      "         796       1.00      1.00      1.00         2\n",
      "         797       0.60      1.00      0.75         3\n",
      "         798       1.00      1.00      1.00         3\n",
      "         799       1.00      1.00      1.00         3\n",
      "         800       1.00      1.00      1.00         1\n",
      "         801       1.00      1.00      1.00         2\n",
      "         802       1.00      1.00      1.00         1\n",
      "         803       1.00      1.00      1.00         1\n",
      "         804       1.00      1.00      1.00         2\n",
      "         805       1.00      1.00      1.00         3\n",
      "         806       1.00      1.00      1.00         2\n",
      "         807       1.00      1.00      1.00         1\n",
      "         808       1.00      1.00      1.00         1\n",
      "         810       0.00      0.00      0.00         1\n",
      "         811       1.00      1.00      1.00         2\n",
      "         812       1.00      1.00      1.00         2\n",
      "         813       1.00      1.00      1.00         2\n",
      "         814       1.00      1.00      1.00         2\n",
      "         815       1.00      1.00      1.00         1\n",
      "         816       1.00      1.00      1.00         2\n",
      "         817       0.03      1.00      0.06         1\n",
      "         818       0.04      0.50      0.07         2\n",
      "         819       1.00      1.00      1.00         2\n",
      "         820       0.75      1.00      0.86         3\n",
      "         821       1.00      1.00      1.00         2\n",
      "         822       1.00      1.00      1.00         1\n",
      "         824       1.00      0.67      0.80         3\n",
      "         825       1.00      1.00      1.00         1\n",
      "         826       1.00      1.00      1.00         1\n",
      "         827       1.00      1.00      1.00         1\n",
      "         828       0.00      0.00      0.00         2\n",
      "         829       0.00      0.00      0.00         2\n",
      "         831       1.00      1.00      1.00         3\n",
      "         833       1.00      1.00      1.00         2\n",
      "         834       1.00      1.00      1.00         1\n",
      "         836       1.00      1.00      1.00         1\n",
      "         837       0.00      0.00      0.00         5\n",
      "         838       1.00      1.00      1.00         1\n",
      "         839       1.00      1.00      1.00         3\n",
      "         842       1.00      1.00      1.00         2\n",
      "         844       1.00      1.00      1.00         2\n",
      "         845       1.00      1.00      1.00         1\n",
      "         846       1.00      1.00      1.00         3\n",
      "         847       1.00      1.00      1.00         1\n",
      "         848       1.00      1.00      1.00         2\n",
      "         849       1.00      1.00      1.00         1\n",
      "         850       1.00      1.00      1.00         4\n",
      "         851       1.00      1.00      1.00         2\n",
      "         852       1.00      1.00      1.00         2\n",
      "         853       1.00      1.00      1.00         2\n",
      "         854       1.00      1.00      1.00         4\n",
      "         855       1.00      1.00      1.00         2\n",
      "         856       1.00      1.00      1.00         3\n",
      "         857       1.00      1.00      1.00         3\n",
      "         858       0.00      0.00      0.00         3\n",
      "         859       1.00      1.00      1.00         2\n",
      "         860       1.00      0.67      0.80         3\n",
      "         861       1.00      1.00      1.00         3\n",
      "         862       0.00      0.00      0.00         1\n",
      "         864       1.00      1.00      1.00         1\n",
      "         865       1.00      1.00      1.00         3\n",
      "         866       1.00      1.00      1.00         3\n",
      "         867       1.00      1.00      1.00         3\n",
      "         868       1.00      1.00      1.00         2\n",
      "         869       1.00      1.00      1.00         3\n",
      "         870       0.75      1.00      0.86         3\n",
      "         871       1.00      1.00      1.00         1\n",
      "         872       1.00      1.00      1.00         2\n",
      "         873       1.00      1.00      1.00         4\n",
      "         874       1.00      1.00      1.00         2\n",
      "         875       1.00      1.00      1.00         2\n",
      "         876       1.00      1.00      1.00         1\n",
      "         877       1.00      1.00      1.00         2\n",
      "         878       1.00      1.00      1.00         3\n",
      "         879       1.00      1.00      1.00         2\n",
      "         880       1.00      1.00      1.00         3\n",
      "         881       1.00      1.00      1.00         3\n",
      "         882       1.00      1.00      1.00         3\n",
      "         883       1.00      1.00      1.00         1\n",
      "         884       1.00      1.00      1.00         1\n",
      "         885       1.00      1.00      1.00         2\n",
      "         886       0.40      1.00      0.57         2\n",
      "         887       1.00      1.00      1.00         1\n",
      "         889       1.00      1.00      1.00         2\n",
      "         890       1.00      1.00      1.00         3\n",
      "         891       1.00      1.00      1.00         3\n",
      "         892       0.00      0.00      0.00         2\n",
      "         893       1.00      1.00      1.00         2\n",
      "         895       1.00      1.00      1.00         4\n",
      "         896       1.00      1.00      1.00         2\n",
      "         897       1.00      1.00      1.00         2\n",
      "         898       1.00      1.00      1.00         1\n",
      "         899       1.00      1.00      1.00         2\n",
      "         900       1.00      1.00      1.00         2\n",
      "         901       1.00      1.00      1.00         4\n",
      "         902       1.00      1.00      1.00         2\n",
      "         903       1.00      1.00      1.00         2\n",
      "         904       1.00      1.00      1.00         1\n",
      "         905       1.00      1.00      1.00         1\n",
      "         906       1.00      1.00      1.00         3\n",
      "         907       1.00      1.00      1.00         2\n",
      "         908       1.00      1.00      1.00         2\n",
      "         910       1.00      1.00      1.00         2\n",
      "         911       1.00      1.00      1.00         1\n",
      "         913       1.00      1.00      1.00         2\n",
      "         915       1.00      1.00      1.00         3\n",
      "         916       1.00      1.00      1.00         1\n",
      "         918       1.00      1.00      1.00         2\n",
      "         919       1.00      1.00      1.00         4\n",
      "         922       1.00      1.00      1.00         1\n",
      "         923       1.00      1.00      1.00         4\n",
      "         924       1.00      1.00      1.00         6\n",
      "         925       1.00      1.00      1.00         2\n",
      "         926       1.00      1.00      1.00         2\n",
      "         927       0.00      0.00      0.00         1\n",
      "         928       1.00      1.00      1.00         2\n",
      "         929       0.67      1.00      0.80         2\n",
      "         930       1.00      1.00      1.00         1\n",
      "         931       1.00      1.00      1.00         2\n",
      "         934       1.00      1.00      1.00         2\n",
      "         937       1.00      1.00      1.00         1\n",
      "         940       0.00      0.00      0.00         3\n",
      "         942       1.00      1.00      1.00         1\n",
      "         946       1.00      1.00      1.00         1\n",
      "         947       1.00      1.00      1.00         1\n",
      "         948       1.00      1.00      1.00         1\n",
      "         949       1.00      1.00      1.00         2\n",
      "         951       1.00      1.00      1.00         3\n",
      "         952       0.00      0.00      0.00         1\n",
      "         953       1.00      1.00      1.00         1\n",
      "         954       1.00      1.00      1.00         2\n",
      "         955       0.00      0.00      0.00         3\n",
      "         956       1.00      1.00      1.00         1\n",
      "         957       1.00      1.00      1.00         1\n",
      "         958       1.00      1.00      1.00         1\n",
      "         959       0.50      1.00      0.67         1\n",
      "         960       0.00      0.00      0.00         4\n",
      "         961       1.00      1.00      1.00         2\n",
      "         962       1.00      1.00      1.00         1\n",
      "         963       1.00      1.00      1.00         1\n",
      "         964       1.00      1.00      1.00         3\n",
      "         965       1.00      1.00      1.00         3\n",
      "         966       1.00      1.00      1.00         1\n",
      "         967       1.00      1.00      1.00         1\n",
      "         968       1.00      1.00      1.00         3\n",
      "         970       1.00      1.00      1.00         2\n",
      "         971       1.00      1.00      1.00         4\n",
      "         972       0.50      1.00      0.67         2\n",
      "         973       1.00      1.00      1.00         1\n",
      "         974       0.00      0.00      0.00         1\n",
      "         975       1.00      1.00      1.00         2\n",
      "         977       0.00      0.00      0.00         2\n",
      "         978       1.00      1.00      1.00         1\n",
      "         979       1.00      1.00      1.00         2\n",
      "         980       1.00      1.00      1.00         1\n",
      "         981       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85      1699\n",
      "   macro avg       0.84      0.85      0.84      1699\n",
      "weighted avg       0.85      0.85      0.84      1699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict([features_test,x_title_test,x_des_test], batch_size=10, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_encoded_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92fe11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26168e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
