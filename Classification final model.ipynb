{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd39f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from os import makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2ae685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5671535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2098976734409195149\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 7806648320\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 12330691707793407216\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0a:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cccf188b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LabelName</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/027rn</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>The Dominican Republic is a country located on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/017dcd</td>\n",
       "      <td>Mighty Morphin Power Rangers</td>\n",
       "      <td>Mighty Morphin Power Rangers is an American su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/01sl1q</td>\n",
       "      <td>Michelle Rodriguez</td>\n",
       "      <td>Mayte Michelle Rodriguez is an American actres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/0cnk2q</td>\n",
       "      <td>Australia national football team</td>\n",
       "      <td>The Australia men's national soccer team repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/02_j1w</td>\n",
       "      <td>Defender</td>\n",
       "      <td>In the sport of association football, a defend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14179</th>\n",
       "      <td>/m/0dlj8q2</td>\n",
       "      <td>Le Monde's 100 Books of the Century</td>\n",
       "      <td>The 100 Books of the Century is a list of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14180</th>\n",
       "      <td>/m/05zp8</td>\n",
       "      <td>Palace</td>\n",
       "      <td>A palace is a grand residence, especially a ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14181</th>\n",
       "      <td>/m/024030</td>\n",
       "      <td>Padma Vibhushan</td>\n",
       "      <td>The Padma Vibhushan is the second-highest civi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14182</th>\n",
       "      <td>/m/02y_9cf</td>\n",
       "      <td>Ethiopian Empire</td>\n",
       "      <td>The Ethiopian Empire, also formerly known by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14183</th>\n",
       "      <td>/m/0fkrk</td>\n",
       "      <td>Grasses</td>\n",
       "      <td>Poaceae or Gramineae is a large and nearly ubi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14184 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        LabelName                                 name  \\\n",
       "0        /m/027rn                   Dominican Republic   \n",
       "1       /m/017dcd         Mighty Morphin Power Rangers   \n",
       "2       /m/01sl1q                   Michelle Rodriguez   \n",
       "3       /m/0cnk2q     Australia national football team   \n",
       "4       /m/02_j1w                             Defender   \n",
       "...           ...                                  ...   \n",
       "14179  /m/0dlj8q2  Le Monde's 100 Books of the Century   \n",
       "14180    /m/05zp8                               Palace   \n",
       "14181   /m/024030                      Padma Vibhushan   \n",
       "14182  /m/02y_9cf                     Ethiopian Empire   \n",
       "14183    /m/0fkrk                              Grasses   \n",
       "\n",
       "                                             description  \n",
       "0      The Dominican Republic is a country located on...  \n",
       "1      Mighty Morphin Power Rangers is an American su...  \n",
       "2      Mayte Michelle Rodriguez is an American actres...  \n",
       "3      The Australia men's national soccer team repre...  \n",
       "4      In the sport of association football, a defend...  \n",
       "...                                                  ...  \n",
       "14179  The 100 Books of the Century is a list of the ...  \n",
       "14180  A palace is a grand residence, especially a ro...  \n",
       "14181  The Padma Vibhushan is the second-highest civi...  \n",
       "14182  The Ethiopian Empire, also formerly known by t...  \n",
       "14183  Poaceae or Gramineae is a large and nearly ubi...  \n",
       "\n",
       "[14184 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_des = pd.read_csv('D:\\RMBI_MMKG_data\\img_des.csv')\n",
    "img_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23646b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb92fb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LabelName</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/027rn</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>The Dominican Republic is a country located on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/017dcd</td>\n",
       "      <td>Mighty Morphin Power Rangers</td>\n",
       "      <td>Mighty Morphin Power Rangers is an American su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/01sl1q</td>\n",
       "      <td>Michelle Rodriguez</td>\n",
       "      <td>Mayte Michelle Rodriguez is an American actres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/0cnk2q</td>\n",
       "      <td>Australia national football team</td>\n",
       "      <td>The Australia men's national soccer team repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/02_j1w</td>\n",
       "      <td>Defender</td>\n",
       "      <td>In the sport of association football, a defend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>/m/01b9ck</td>\n",
       "      <td>Darryl F. Zanuck</td>\n",
       "      <td>Darryl Francis Zanuck was an American film pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>/m/011ywj</td>\n",
       "      <td>Gosford Park</td>\n",
       "      <td>Gosford Park is a 2001 satirical black comedy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>/m/0325pb</td>\n",
       "      <td>Alpha Delta Pi</td>\n",
       "      <td>Alpha Delta Pi, commonly known as ADPi, is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>/m/0mnrb</td>\n",
       "      <td>Henrico County</td>\n",
       "      <td>Henrico County, officially the County of Henri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>/m/05sxg2</td>\n",
       "      <td>Theatrical producer</td>\n",
       "      <td>A theatrical producer is a person who oversees...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LabelName                              name  \\\n",
       "0     /m/027rn                Dominican Republic   \n",
       "1    /m/017dcd      Mighty Morphin Power Rangers   \n",
       "2    /m/01sl1q                Michelle Rodriguez   \n",
       "3    /m/0cnk2q  Australia national football team   \n",
       "4    /m/02_j1w                          Defender   \n",
       "..         ...                               ...   \n",
       "995  /m/01b9ck                  Darryl F. Zanuck   \n",
       "996  /m/011ywj                      Gosford Park   \n",
       "997  /m/0325pb                    Alpha Delta Pi   \n",
       "998   /m/0mnrb                    Henrico County   \n",
       "999  /m/05sxg2               Theatrical producer   \n",
       "\n",
       "                                           description  \n",
       "0    The Dominican Republic is a country located on...  \n",
       "1    Mighty Morphin Power Rangers is an American su...  \n",
       "2    Mayte Michelle Rodriguez is an American actres...  \n",
       "3    The Australia men's national soccer team repre...  \n",
       "4    In the sport of association football, a defend...  \n",
       "..                                                 ...  \n",
       "995  Darryl Francis Zanuck was an American film pro...  \n",
       "996  Gosford Park is a 2001 satirical black comedy ...  \n",
       "997  Alpha Delta Pi, commonly known as ADPi, is an ...  \n",
       "998  Henrico County, officially the County of Henri...  \n",
       "999  A theatrical producer is a person who oversees...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_des_trunc = img_des.head(SIZE)\n",
    "img_des_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0464e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LabelName</th>\n",
       "      <th>name</th>\n",
       "      <th>title_vec</th>\n",
       "      <th>des_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/027rn</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/017dcd</td>\n",
       "      <td>Mighty Morphin Power Rangers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/01sl1q</td>\n",
       "      <td>Michelle Rodriguez</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/0cnk2q</td>\n",
       "      <td>Australia national football team</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/02_j1w</td>\n",
       "      <td>Defender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>/m/01b9ck</td>\n",
       "      <td>Darryl F. Zanuck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>/m/011ywj</td>\n",
       "      <td>Gosford Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>/m/0325pb</td>\n",
       "      <td>Alpha Delta Pi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>/m/0mnrb</td>\n",
       "      <td>Henrico County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>/m/05sxg2</td>\n",
       "      <td>Theatrical producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LabelName                              name title_vec des_vec\n",
       "0     /m/027rn                Dominican Republic       NaN     NaN\n",
       "1    /m/017dcd      Mighty Morphin Power Rangers       NaN     NaN\n",
       "2    /m/01sl1q                Michelle Rodriguez       NaN     NaN\n",
       "3    /m/0cnk2q  Australia national football team       NaN     NaN\n",
       "4    /m/02_j1w                          Defender       NaN     NaN\n",
       "..         ...                               ...       ...     ...\n",
       "995  /m/01b9ck                  Darryl F. Zanuck       NaN     NaN\n",
       "996  /m/011ywj                      Gosford Park       NaN     NaN\n",
       "997  /m/0325pb                    Alpha Delta Pi       NaN     NaN\n",
       "998   /m/0mnrb                    Henrico County       NaN     NaN\n",
       "999  /m/05sxg2               Theatrical producer       NaN     NaN\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec = pd.DataFrame(columns=['LabelName','name','title_vec','des_vec'])\n",
    "text_vec['LabelName'] = img_des_trunc['LabelName']\n",
    "text_vec['name'] = img_des_trunc['name']\n",
    "text_vec['title_vec']=text_vec['title_vec'].astype(object)\n",
    "text_vec['des_vec']=text_vec['des_vec'].astype(object)\n",
    "text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a034f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\envs\\gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.LayerNorm.bias', 'predictions.decoder.bias', 'predictions.decoder.weight', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.LayerNorm.weight', 'predictions.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LabelName</th>\n",
       "      <th>name</th>\n",
       "      <th>title_vec</th>\n",
       "      <th>des_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/027rn</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>[0.4945737, 1.3592469, 1.282383, 0.01269114, -...</td>\n",
       "      <td>[0.7342588, -0.70393395, 1.6656038, 0.67461014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/017dcd</td>\n",
       "      <td>Mighty Morphin Power Rangers</td>\n",
       "      <td>[1.6969184, 1.8559471, 0.8122708, -0.40268016,...</td>\n",
       "      <td>[0.025732398, -0.7696621, 2.172137, 1.2750009,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/01sl1q</td>\n",
       "      <td>Michelle Rodriguez</td>\n",
       "      <td>[1.2370641, 2.8018966, 0.16598952, -0.5138393,...</td>\n",
       "      <td>[0.6779196, -0.15636724, 0.9539355, 0.6223599,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/0cnk2q</td>\n",
       "      <td>Australia national football team</td>\n",
       "      <td>[-0.34985536, 1.8396395, 1.8012114, -0.3399124...</td>\n",
       "      <td>[-0.7440083, 0.010402456, 2.7207577, 0.6726733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/02_j1w</td>\n",
       "      <td>Defender</td>\n",
       "      <td>[0.10609877, 1.8506274, 1.07485, -0.12472837, ...</td>\n",
       "      <td>[-0.1949073, -0.38760465, 3.056767, 0.1185953,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>/m/01b9ck</td>\n",
       "      <td>Darryl F. Zanuck</td>\n",
       "      <td>[1.229999, 2.4127681, 0.94314957, -1.3280284, ...</td>\n",
       "      <td>[0.73823285, -0.08005962, 0.827093, 0.8234503,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>/m/011ywj</td>\n",
       "      <td>Gosford Park</td>\n",
       "      <td>[0.7568916, 1.5736562, 0.8222938, -0.13049412,...</td>\n",
       "      <td>[0.26722866, -0.9173725, 1.927658, 0.5772505, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>/m/0325pb</td>\n",
       "      <td>Alpha Delta Pi</td>\n",
       "      <td>[0.5692497, 1.3098, 1.3415865, -0.55102956, -0...</td>\n",
       "      <td>[0.18281287, -0.25513795, 2.1837523, 0.3496461...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>/m/0mnrb</td>\n",
       "      <td>Henrico County</td>\n",
       "      <td>[0.059751034, 0.558505, 0.9079651, -0.01371228...</td>\n",
       "      <td>[-0.95366466, -0.1571609, 1.9237427, -0.214625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>/m/05sxg2</td>\n",
       "      <td>Theatrical producer</td>\n",
       "      <td>[0.7791275, 1.6730425, 0.708414, -0.34585774, ...</td>\n",
       "      <td>[0.7939751, 0.95126754, 0.88291603, 1.622468, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LabelName                              name  \\\n",
       "0     /m/027rn                Dominican Republic   \n",
       "1    /m/017dcd      Mighty Morphin Power Rangers   \n",
       "2    /m/01sl1q                Michelle Rodriguez   \n",
       "3    /m/0cnk2q  Australia national football team   \n",
       "4    /m/02_j1w                          Defender   \n",
       "..         ...                               ...   \n",
       "995  /m/01b9ck                  Darryl F. Zanuck   \n",
       "996  /m/011ywj                      Gosford Park   \n",
       "997  /m/0325pb                    Alpha Delta Pi   \n",
       "998   /m/0mnrb                    Henrico County   \n",
       "999  /m/05sxg2               Theatrical producer   \n",
       "\n",
       "                                             title_vec  \\\n",
       "0    [0.4945737, 1.3592469, 1.282383, 0.01269114, -...   \n",
       "1    [1.6969184, 1.8559471, 0.8122708, -0.40268016,...   \n",
       "2    [1.2370641, 2.8018966, 0.16598952, -0.5138393,...   \n",
       "3    [-0.34985536, 1.8396395, 1.8012114, -0.3399124...   \n",
       "4    [0.10609877, 1.8506274, 1.07485, -0.12472837, ...   \n",
       "..                                                 ...   \n",
       "995  [1.229999, 2.4127681, 0.94314957, -1.3280284, ...   \n",
       "996  [0.7568916, 1.5736562, 0.8222938, -0.13049412,...   \n",
       "997  [0.5692497, 1.3098, 1.3415865, -0.55102956, -0...   \n",
       "998  [0.059751034, 0.558505, 0.9079651, -0.01371228...   \n",
       "999  [0.7791275, 1.6730425, 0.708414, -0.34585774, ...   \n",
       "\n",
       "                                               des_vec  \n",
       "0    [0.7342588, -0.70393395, 1.6656038, 0.67461014...  \n",
       "1    [0.025732398, -0.7696621, 2.172137, 1.2750009,...  \n",
       "2    [0.6779196, -0.15636724, 0.9539355, 0.6223599,...  \n",
       "3    [-0.7440083, 0.010402456, 2.7207577, 0.6726733...  \n",
       "4    [-0.1949073, -0.38760465, 3.056767, 0.1185953,...  \n",
       "..                                                 ...  \n",
       "995  [0.73823285, -0.08005962, 0.827093, 0.8234503,...  \n",
       "996  [0.26722866, -0.9173725, 1.927658, 0.5772505, ...  \n",
       "997  [0.18281287, -0.25513795, 2.1837523, 0.3496461...  \n",
       "998  [-0.95366466, -0.1571609, 1.9237427, -0.214625...  \n",
       "999  [0.7939751, 0.95126754, 0.88291603, 1.622468, ...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sister\n",
    "sentence_embedding = sister.BertEmbedding(lang=\"en\")\n",
    "\n",
    "for i in range(SIZE):\n",
    "    if (pd.notnull(img_des_trunc['name'][i])):\n",
    "        text_vec['title_vec'][i] = sentence_embedding(img_des_trunc['name'][i])\n",
    "    if (pd.notnull(img_des_trunc['description'][i])):\n",
    "        text_vec['des_vec'][i] = sentence_embedding(img_des_trunc['description'][i]) \n",
    "text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "307c65e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [0.7342588, -0.70393395, 1.6656038, 0.67461014...\n",
       "1      [0.025732398, -0.7696621, 2.172137, 1.2750009,...\n",
       "2      [0.6779196, -0.15636724, 0.9539355, 0.6223599,...\n",
       "3      [-0.7440083, 0.010402456, 2.7207577, 0.6726733...\n",
       "4      [-0.1949073, -0.38760465, 3.056767, 0.1185953,...\n",
       "                             ...                        \n",
       "995    [0.73823285, -0.08005962, 0.827093, 0.8234503,...\n",
       "996    [0.26722866, -0.9173725, 1.927658, 0.5772505, ...\n",
       "997    [0.18281287, -0.25513795, 2.1837523, 0.3496461...\n",
       "998    [-0.95366466, -0.1571609, 1.9237427, -0.214625...\n",
       "999    [0.7939751, 0.95126754, 0.88291603, 1.622468, ...\n",
       "Name: des_vec, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec['des_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89721b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\envs\\gpu\\lib\\site-packages\\PIL\\TiffImagePlugin.py:845: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\World War II\\img_1460.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Crystal Palace F.C.\\img_2403.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Crystal Palace F.C.\\img_2404.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\United Nations\\img_3556.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Marvel Entertainment\\img_4278.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Billy Connolly\\img_5103.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\APOEL FC\\img_5873.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Fayetteville\\img_104019.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\SG Dynamo Dresden\\img_6375.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Shrek\\img_6777.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Dan Povenmire\\img_7498.jpg\n",
      "D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader\\Election\\img_57947.jpg\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "x_img = []\n",
    "x_title = []\n",
    "x_des = []\n",
    "import os\n",
    "\n",
    "for i in range(SIZE):\n",
    "    path_of_the_directory = os.path.join('D:\\RMBI_MMKG_data\\Bulk-Bing-Image-downloader', img_des['name'][i])\n",
    "    ext = ('.jpg')\n",
    "    for path, dirc, files in os.walk(path_of_the_directory):\n",
    "        for name in files:\n",
    "            if name.endswith(ext):\n",
    "                \n",
    "                img_path = os.path.join(path, name)\n",
    "                try:                \n",
    "                    img = image.load_img(img_path, target_size=(224, 224))\n",
    "                    img = image.img_to_array(img)\n",
    "                \n",
    "                    x_img.append(img)\n",
    "                    y.append(img_des['name'][i])\n",
    "                    x_title.append(text_vec['title_vec'][i])\n",
    "                    x_des.append(text_vec['des_vec'][i])\n",
    "                except:\n",
    "                    print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "893b3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "x_img = np.array(x_img)\n",
    "x_title = np.array(x_title)\n",
    "x_des = np.array(x_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b355ccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8493,)\n",
      "(8493, 224, 224, 3)\n",
      "(8493, 768)\n",
      "(8493, 768)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(x_img.shape)\n",
    "print(x_title.shape)\n",
    "print(x_des.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "608e2411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dominican Republic', 'Dominican Republic', 'Dominican Republic',\n",
       "       ..., 'Theatrical producer', 'Theatrical producer',\n",
       "       'Theatrical producer'], dtype='<U97')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0096a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y_encoded = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a30e1218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([265, 265, 265, ..., 890, 890, 890])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a1aca36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e42d8087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8493, 983)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1e78273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_img_train, x_img_test, x_title_train, x_title_test,x_des_train, x_des_test, y_one_hot_train, y_one_hot_test, y_encoded_train, y_encoded_test = train_test_split(x_img, x_title, x_des, y_one_hot, y_encoded, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c1b5399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 93.,  91.,  79.],\n",
       "         [ 43.,  45.,  34.],\n",
       "         [  0.,   0.,   2.],\n",
       "         ...,\n",
       "         [ 36.,  40.,  49.],\n",
       "         [  0.,   6.,   0.],\n",
       "         [ 20.,  59.,  98.]],\n",
       "\n",
       "        [[ 15.,  18.,  11.],\n",
       "         [  6.,   6.,   0.],\n",
       "         [ 73.,  77.,  54.],\n",
       "         ...,\n",
       "         [ 28.,  25.,  20.],\n",
       "         [  6.,  27.,  18.],\n",
       "         [ 34., 150., 233.]],\n",
       "\n",
       "        [[ 17.,  27.,  26.],\n",
       "         [  5.,   0.,   0.],\n",
       "         [  7.,   6.,   0.],\n",
       "         ...,\n",
       "         [ 29.,  57.,  94.],\n",
       "         [ 36.,  72.,  70.],\n",
       "         [ 33., 102., 157.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 11.,  19.,   6.],\n",
       "         [  7.,  15.,   4.],\n",
       "         [  2.,  10.,   0.],\n",
       "         ...,\n",
       "         [ 18.,  14.,  13.],\n",
       "         [ 20.,  16.,  15.],\n",
       "         [ 19.,  15.,  14.]],\n",
       "\n",
       "        [[  0.,   7.,   0.],\n",
       "         [  1.,   9.,   0.],\n",
       "         [ 20.,  29.,  12.],\n",
       "         ...,\n",
       "         [ 17.,  13.,  12.],\n",
       "         [  9.,   5.,   4.],\n",
       "         [ 17.,  13.,  12.]],\n",
       "\n",
       "        [[  7.,  15.,   2.],\n",
       "         [ 10.,  18.,   7.],\n",
       "         [  5.,  14.,   0.],\n",
       "         ...,\n",
       "         [ 21.,  17.,  16.],\n",
       "         [ 18.,  14.,  13.],\n",
       "         [ 13.,   9.,   8.]]],\n",
       "\n",
       "\n",
       "       [[[239., 238., 233.],\n",
       "         [240., 239., 234.],\n",
       "         [239., 240., 234.],\n",
       "         ...,\n",
       "         [245., 247., 244.],\n",
       "         [245., 247., 244.],\n",
       "         [246., 248., 245.]],\n",
       "\n",
       "        [[239., 238., 233.],\n",
       "         [240., 239., 234.],\n",
       "         [239., 240., 234.],\n",
       "         ...,\n",
       "         [245., 247., 244.],\n",
       "         [245., 247., 244.],\n",
       "         [245., 247., 244.]],\n",
       "\n",
       "        [[239., 238., 233.],\n",
       "         [240., 239., 234.],\n",
       "         [239., 240., 234.],\n",
       "         ...,\n",
       "         [245., 247., 244.],\n",
       "         [245., 247., 244.],\n",
       "         [245., 247., 244.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 38.,  39.,  44.],\n",
       "         [ 36.,  37.,  42.],\n",
       "         [ 35.,  35.,  45.],\n",
       "         ...,\n",
       "         [242., 241., 236.],\n",
       "         [243., 242., 237.],\n",
       "         [241., 240., 238.]],\n",
       "\n",
       "        [[ 38.,  39.,  44.],\n",
       "         [ 36.,  37.,  42.],\n",
       "         [ 38.,  38.,  48.],\n",
       "         ...,\n",
       "         [236., 231., 225.],\n",
       "         [235., 230., 224.],\n",
       "         [236., 231., 227.]],\n",
       "\n",
       "        [[ 42.,  43.,  48.],\n",
       "         [ 38.,  39.,  44.],\n",
       "         [ 38.,  39.,  44.],\n",
       "         ...,\n",
       "         [228., 223., 217.],\n",
       "         [226., 221., 215.],\n",
       "         [226., 221., 215.]]],\n",
       "\n",
       "\n",
       "       [[[221., 217., 214.],\n",
       "         [222., 219., 214.],\n",
       "         [220., 217., 212.],\n",
       "         ...,\n",
       "         [  0., 117., 210.],\n",
       "         [  0., 116., 209.],\n",
       "         [  0., 117., 210.]],\n",
       "\n",
       "        [[225., 222., 215.],\n",
       "         [225., 222., 215.],\n",
       "         [224., 221., 214.],\n",
       "         ...,\n",
       "         [  0., 116., 209.],\n",
       "         [  1., 118., 211.],\n",
       "         [  0., 117., 210.]],\n",
       "\n",
       "        [[225., 220., 214.],\n",
       "         [227., 222., 216.],\n",
       "         [226., 221., 215.],\n",
       "         ...,\n",
       "         [  1., 118., 211.],\n",
       "         [  1., 118., 211.],\n",
       "         [  1., 118., 211.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 62.,  52.,  53.],\n",
       "         [ 94.,  88.,  92.],\n",
       "         [199., 203., 228.],\n",
       "         ...,\n",
       "         [ 70.,  63.,  55.],\n",
       "         [ 35.,  31.,  30.],\n",
       "         [137., 119., 115.]],\n",
       "\n",
       "        [[ 64.,  54.,  53.],\n",
       "         [ 53.,  44.,  35.],\n",
       "         [128., 129., 149.],\n",
       "         ...,\n",
       "         [ 75.,  63.,  51.],\n",
       "         [101.,  91.,  81.],\n",
       "         [119.,  83.,  67.]],\n",
       "\n",
       "        [[ 57.,  47.,  45.],\n",
       "         [ 68.,  62.,  66.],\n",
       "         [ 32.,  30.,  41.],\n",
       "         ...,\n",
       "         [220., 198., 161.],\n",
       "         [ 74.,  50.,  12.],\n",
       "         [ 72.,  50.,  29.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 98., 150., 207.],\n",
       "         [ 97., 149., 206.],\n",
       "         [ 98., 150., 207.],\n",
       "         ...,\n",
       "         [ 82., 144., 203.],\n",
       "         [ 82., 144., 203.],\n",
       "         [ 83., 145., 204.]],\n",
       "\n",
       "        [[ 96., 151., 207.],\n",
       "         [ 97., 152., 208.],\n",
       "         [ 96., 151., 207.],\n",
       "         ...,\n",
       "         [ 83., 145., 204.],\n",
       "         [ 83., 145., 204.],\n",
       "         [ 83., 145., 204.]],\n",
       "\n",
       "        [[ 97., 152., 208.],\n",
       "         [ 97., 152., 208.],\n",
       "         [ 97., 152., 208.],\n",
       "         ...,\n",
       "         [ 84., 146., 205.],\n",
       "         [ 84., 146., 205.],\n",
       "         [ 84., 146., 205.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 85., 126.,  56.],\n",
       "         [ 94., 134.,  71.],\n",
       "         [ 62., 101.,  56.],\n",
       "         ...,\n",
       "         [ 66., 102.,  54.],\n",
       "         [ 52.,  86.,  49.],\n",
       "         [ 34.,  63.,  33.]],\n",
       "\n",
       "        [[ 86., 128.,  62.],\n",
       "         [ 84., 124.,  61.],\n",
       "         [ 53.,  88.,  48.],\n",
       "         ...,\n",
       "         [ 52.,  89.,  48.],\n",
       "         [ 40.,  66.,  39.],\n",
       "         [ 60.,  91.,  49.]],\n",
       "\n",
       "        [[ 53.,  87.,  50.],\n",
       "         [ 79., 114.,  60.],\n",
       "         [ 76., 108.,  59.],\n",
       "         ...,\n",
       "         [ 75., 110.,  56.],\n",
       "         [ 63.,  99.,  53.],\n",
       "         [ 71., 108.,  57.]]],\n",
       "\n",
       "\n",
       "       [[[ 83., 140., 253.],\n",
       "         [ 91., 149., 255.],\n",
       "         [ 94., 151., 255.],\n",
       "         ...,\n",
       "         [ 45., 115., 247.],\n",
       "         [ 44., 112., 247.],\n",
       "         [ 48., 116., 251.]],\n",
       "\n",
       "        [[ 83., 135., 253.],\n",
       "         [ 90., 143., 255.],\n",
       "         [ 89., 145., 254.],\n",
       "         ...,\n",
       "         [ 44., 113., 250.],\n",
       "         [ 46., 114., 249.],\n",
       "         [ 50., 118., 253.]],\n",
       "\n",
       "        [[ 81., 136., 252.],\n",
       "         [ 86., 142., 253.],\n",
       "         [ 88., 144., 255.],\n",
       "         ...,\n",
       "         [ 37., 113., 250.],\n",
       "         [ 43., 115., 253.],\n",
       "         [ 43., 115., 253.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[220.,  66.,   4.],\n",
       "         [195.,  46.,   0.],\n",
       "         [200.,  53.,   2.],\n",
       "         ...,\n",
       "         [144.,  37.,   5.],\n",
       "         [196.,  57.,  16.],\n",
       "         [190.,  55.,   0.]],\n",
       "\n",
       "        [[237.,  80.,  13.],\n",
       "         [195.,  41.,   0.],\n",
       "         [233.,  74.,   9.],\n",
       "         ...,\n",
       "         [ 27.,   0.,   0.],\n",
       "         [151.,  35.,   0.],\n",
       "         [172.,  56.,   5.]],\n",
       "\n",
       "        [[212.,  52.,   0.],\n",
       "         [246.,  84.,   3.],\n",
       "         [200.,  47.,   3.],\n",
       "         ...,\n",
       "         [202.,  76.,  36.],\n",
       "         [ 96.,  26.,  16.],\n",
       "         [173.,  47.,   9.]]],\n",
       "\n",
       "\n",
       "       [[[ 96.,  82.,  99.],\n",
       "         [ 98.,  81.,  99.],\n",
       "         [ 98.,  84.,  97.],\n",
       "         ...,\n",
       "         [108., 112., 137.],\n",
       "         [108., 114., 140.],\n",
       "         [107., 113., 139.]],\n",
       "\n",
       "        [[ 96.,  82.,  97.],\n",
       "         [ 99.,  82.,  98.],\n",
       "         [ 98.,  84.,  97.],\n",
       "         ...,\n",
       "         [109., 115., 141.],\n",
       "         [106., 113., 141.],\n",
       "         [106., 113., 141.]],\n",
       "\n",
       "        [[ 98.,  86., 100.],\n",
       "         [ 98.,  84.,  99.],\n",
       "         [100.,  86.,  99.],\n",
       "         ...,\n",
       "         [103., 112., 141.],\n",
       "         [103., 112., 141.],\n",
       "         [103., 112., 141.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[136.,  62.,  23.],\n",
       "         [138.,  58.,  21.],\n",
       "         [144.,  64.,  11.],\n",
       "         ...,\n",
       "         [126.,  36.,   0.],\n",
       "         [115.,  34.,   4.],\n",
       "         [152.,  60.,  21.]],\n",
       "\n",
       "        [[130.,  54.,  18.],\n",
       "         [127.,  54.,  19.],\n",
       "         [119.,  53.,  19.],\n",
       "         ...,\n",
       "         [112.,  35.,  17.],\n",
       "         [112.,  32.,   5.],\n",
       "         [122.,  38.,   2.]],\n",
       "\n",
       "        [[117.,  52.,  14.],\n",
       "         [ 79.,  22.,   0.],\n",
       "         [ 78.,  19.,   5.],\n",
       "         ...,\n",
       "         [ 42.,   2.,   0.],\n",
       "         [111.,  34.,   6.],\n",
       "         [116.,  32.,   0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7321240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train, x_img_test = x_img_train / 255.0, x_img_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08057125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.3647059 , 0.35686275, 0.30980393],\n",
       "         [0.16862746, 0.1764706 , 0.13333334],\n",
       "         [0.        , 0.        , 0.00784314],\n",
       "         ...,\n",
       "         [0.14117648, 0.15686275, 0.19215687],\n",
       "         [0.        , 0.02352941, 0.        ],\n",
       "         [0.07843138, 0.23137255, 0.38431373]],\n",
       "\n",
       "        [[0.05882353, 0.07058824, 0.04313726],\n",
       "         [0.02352941, 0.02352941, 0.        ],\n",
       "         [0.28627452, 0.3019608 , 0.21176471],\n",
       "         ...,\n",
       "         [0.10980392, 0.09803922, 0.07843138],\n",
       "         [0.02352941, 0.10588235, 0.07058824],\n",
       "         [0.13333334, 0.5882353 , 0.9137255 ]],\n",
       "\n",
       "        [[0.06666667, 0.10588235, 0.10196079],\n",
       "         [0.01960784, 0.        , 0.        ],\n",
       "         [0.02745098, 0.02352941, 0.        ],\n",
       "         ...,\n",
       "         [0.11372549, 0.22352941, 0.36862746],\n",
       "         [0.14117648, 0.28235295, 0.27450982],\n",
       "         [0.12941177, 0.4       , 0.6156863 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.04313726, 0.07450981, 0.02352941],\n",
       "         [0.02745098, 0.05882353, 0.01568628],\n",
       "         [0.00784314, 0.03921569, 0.        ],\n",
       "         ...,\n",
       "         [0.07058824, 0.05490196, 0.05098039],\n",
       "         [0.07843138, 0.0627451 , 0.05882353],\n",
       "         [0.07450981, 0.05882353, 0.05490196]],\n",
       "\n",
       "        [[0.        , 0.02745098, 0.        ],\n",
       "         [0.00392157, 0.03529412, 0.        ],\n",
       "         [0.07843138, 0.11372549, 0.04705882],\n",
       "         ...,\n",
       "         [0.06666667, 0.05098039, 0.04705882],\n",
       "         [0.03529412, 0.01960784, 0.01568628],\n",
       "         [0.06666667, 0.05098039, 0.04705882]],\n",
       "\n",
       "        [[0.02745098, 0.05882353, 0.00784314],\n",
       "         [0.03921569, 0.07058824, 0.02745098],\n",
       "         [0.01960784, 0.05490196, 0.        ],\n",
       "         ...,\n",
       "         [0.08235294, 0.06666667, 0.0627451 ],\n",
       "         [0.07058824, 0.05490196, 0.05098039],\n",
       "         [0.05098039, 0.03529412, 0.03137255]]],\n",
       "\n",
       "\n",
       "       [[[0.9372549 , 0.93333334, 0.9137255 ],\n",
       "         [0.9411765 , 0.9372549 , 0.91764706],\n",
       "         [0.9372549 , 0.9411765 , 0.91764706],\n",
       "         ...,\n",
       "         [0.9607843 , 0.96862745, 0.95686275],\n",
       "         [0.9607843 , 0.96862745, 0.95686275],\n",
       "         [0.9647059 , 0.972549  , 0.9607843 ]],\n",
       "\n",
       "        [[0.9372549 , 0.93333334, 0.9137255 ],\n",
       "         [0.9411765 , 0.9372549 , 0.91764706],\n",
       "         [0.9372549 , 0.9411765 , 0.91764706],\n",
       "         ...,\n",
       "         [0.9607843 , 0.96862745, 0.95686275],\n",
       "         [0.9607843 , 0.96862745, 0.95686275],\n",
       "         [0.9607843 , 0.96862745, 0.95686275]],\n",
       "\n",
       "        [[0.9372549 , 0.93333334, 0.9137255 ],\n",
       "         [0.9411765 , 0.9372549 , 0.91764706],\n",
       "         [0.9372549 , 0.9411765 , 0.91764706],\n",
       "         ...,\n",
       "         [0.9607843 , 0.96862745, 0.95686275],\n",
       "         [0.9607843 , 0.96862745, 0.95686275],\n",
       "         [0.9607843 , 0.96862745, 0.95686275]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.14901961, 0.15294118, 0.17254902],\n",
       "         [0.14117648, 0.14509805, 0.16470589],\n",
       "         [0.13725491, 0.13725491, 0.1764706 ],\n",
       "         ...,\n",
       "         [0.9490196 , 0.94509804, 0.9254902 ],\n",
       "         [0.9529412 , 0.9490196 , 0.92941177],\n",
       "         [0.94509804, 0.9411765 , 0.93333334]],\n",
       "\n",
       "        [[0.14901961, 0.15294118, 0.17254902],\n",
       "         [0.14117648, 0.14509805, 0.16470589],\n",
       "         [0.14901961, 0.14901961, 0.1882353 ],\n",
       "         ...,\n",
       "         [0.9254902 , 0.90588236, 0.88235295],\n",
       "         [0.92156863, 0.9019608 , 0.8784314 ],\n",
       "         [0.9254902 , 0.90588236, 0.8901961 ]],\n",
       "\n",
       "        [[0.16470589, 0.16862746, 0.1882353 ],\n",
       "         [0.14901961, 0.15294118, 0.17254902],\n",
       "         [0.14901961, 0.15294118, 0.17254902],\n",
       "         ...,\n",
       "         [0.89411765, 0.8745098 , 0.8509804 ],\n",
       "         [0.8862745 , 0.8666667 , 0.84313726],\n",
       "         [0.8862745 , 0.8666667 , 0.84313726]]],\n",
       "\n",
       "\n",
       "       [[[0.8666667 , 0.8509804 , 0.8392157 ],\n",
       "         [0.87058824, 0.85882354, 0.8392157 ],\n",
       "         [0.8627451 , 0.8509804 , 0.83137256],\n",
       "         ...,\n",
       "         [0.        , 0.45882353, 0.8235294 ],\n",
       "         [0.        , 0.45490196, 0.81960785],\n",
       "         [0.        , 0.45882353, 0.8235294 ]],\n",
       "\n",
       "        [[0.88235295, 0.87058824, 0.84313726],\n",
       "         [0.88235295, 0.87058824, 0.84313726],\n",
       "         [0.8784314 , 0.8666667 , 0.8392157 ],\n",
       "         ...,\n",
       "         [0.        , 0.45490196, 0.81960785],\n",
       "         [0.00392157, 0.4627451 , 0.827451  ],\n",
       "         [0.        , 0.45882353, 0.8235294 ]],\n",
       "\n",
       "        [[0.88235295, 0.8627451 , 0.8392157 ],\n",
       "         [0.8901961 , 0.87058824, 0.84705883],\n",
       "         [0.8862745 , 0.8666667 , 0.84313726],\n",
       "         ...,\n",
       "         [0.00392157, 0.4627451 , 0.827451  ],\n",
       "         [0.00392157, 0.4627451 , 0.827451  ],\n",
       "         [0.00392157, 0.4627451 , 0.827451  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.24313726, 0.20392157, 0.20784314],\n",
       "         [0.36862746, 0.34509805, 0.36078432],\n",
       "         [0.78039217, 0.79607844, 0.89411765],\n",
       "         ...,\n",
       "         [0.27450982, 0.24705882, 0.21568628],\n",
       "         [0.13725491, 0.12156863, 0.11764706],\n",
       "         [0.5372549 , 0.46666667, 0.4509804 ]],\n",
       "\n",
       "        [[0.2509804 , 0.21176471, 0.20784314],\n",
       "         [0.20784314, 0.17254902, 0.13725491],\n",
       "         [0.5019608 , 0.5058824 , 0.58431375],\n",
       "         ...,\n",
       "         [0.29411766, 0.24705882, 0.2       ],\n",
       "         [0.39607844, 0.35686275, 0.31764707],\n",
       "         [0.46666667, 0.3254902 , 0.2627451 ]],\n",
       "\n",
       "        [[0.22352941, 0.18431373, 0.1764706 ],\n",
       "         [0.26666668, 0.24313726, 0.25882354],\n",
       "         [0.1254902 , 0.11764706, 0.16078432],\n",
       "         ...,\n",
       "         [0.8627451 , 0.7764706 , 0.6313726 ],\n",
       "         [0.2901961 , 0.19607843, 0.04705882],\n",
       "         [0.28235295, 0.19607843, 0.11372549]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.38431373, 0.5882353 , 0.8117647 ],\n",
       "         [0.38039216, 0.58431375, 0.80784315],\n",
       "         [0.38431373, 0.5882353 , 0.8117647 ],\n",
       "         ...,\n",
       "         [0.32156864, 0.5647059 , 0.79607844],\n",
       "         [0.32156864, 0.5647059 , 0.79607844],\n",
       "         [0.3254902 , 0.5686275 , 0.8       ]],\n",
       "\n",
       "        [[0.3764706 , 0.5921569 , 0.8117647 ],\n",
       "         [0.38039216, 0.59607846, 0.8156863 ],\n",
       "         [0.3764706 , 0.5921569 , 0.8117647 ],\n",
       "         ...,\n",
       "         [0.3254902 , 0.5686275 , 0.8       ],\n",
       "         [0.3254902 , 0.5686275 , 0.8       ],\n",
       "         [0.3254902 , 0.5686275 , 0.8       ]],\n",
       "\n",
       "        [[0.38039216, 0.59607846, 0.8156863 ],\n",
       "         [0.38039216, 0.59607846, 0.8156863 ],\n",
       "         [0.38039216, 0.59607846, 0.8156863 ],\n",
       "         ...,\n",
       "         [0.32941177, 0.57254905, 0.8039216 ],\n",
       "         [0.32941177, 0.57254905, 0.8039216 ],\n",
       "         [0.32941177, 0.57254905, 0.8039216 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.33333334, 0.49411765, 0.21960784],\n",
       "         [0.36862746, 0.5254902 , 0.2784314 ],\n",
       "         [0.24313726, 0.39607844, 0.21960784],\n",
       "         ...,\n",
       "         [0.25882354, 0.4       , 0.21176471],\n",
       "         [0.20392157, 0.3372549 , 0.19215687],\n",
       "         [0.13333334, 0.24705882, 0.12941177]],\n",
       "\n",
       "        [[0.3372549 , 0.5019608 , 0.24313726],\n",
       "         [0.32941177, 0.4862745 , 0.23921569],\n",
       "         [0.20784314, 0.34509805, 0.1882353 ],\n",
       "         ...,\n",
       "         [0.20392157, 0.34901962, 0.1882353 ],\n",
       "         [0.15686275, 0.25882354, 0.15294118],\n",
       "         [0.23529412, 0.35686275, 0.19215687]],\n",
       "\n",
       "        [[0.20784314, 0.34117648, 0.19607843],\n",
       "         [0.30980393, 0.44705883, 0.23529412],\n",
       "         [0.29803923, 0.42352942, 0.23137255],\n",
       "         ...,\n",
       "         [0.29411766, 0.43137255, 0.21960784],\n",
       "         [0.24705882, 0.3882353 , 0.20784314],\n",
       "         [0.2784314 , 0.42352942, 0.22352941]]],\n",
       "\n",
       "\n",
       "       [[[0.3254902 , 0.54901963, 0.99215686],\n",
       "         [0.35686275, 0.58431375, 1.        ],\n",
       "         [0.36862746, 0.5921569 , 1.        ],\n",
       "         ...,\n",
       "         [0.1764706 , 0.4509804 , 0.96862745],\n",
       "         [0.17254902, 0.4392157 , 0.96862745],\n",
       "         [0.1882353 , 0.45490196, 0.9843137 ]],\n",
       "\n",
       "        [[0.3254902 , 0.5294118 , 0.99215686],\n",
       "         [0.3529412 , 0.56078434, 1.        ],\n",
       "         [0.34901962, 0.5686275 , 0.99607843],\n",
       "         ...,\n",
       "         [0.17254902, 0.44313726, 0.98039216],\n",
       "         [0.18039216, 0.44705883, 0.9764706 ],\n",
       "         [0.19607843, 0.4627451 , 0.99215686]],\n",
       "\n",
       "        [[0.31764707, 0.53333336, 0.9882353 ],\n",
       "         [0.3372549 , 0.5568628 , 0.99215686],\n",
       "         [0.34509805, 0.5647059 , 1.        ],\n",
       "         ...,\n",
       "         [0.14509805, 0.44313726, 0.98039216],\n",
       "         [0.16862746, 0.4509804 , 0.99215686],\n",
       "         [0.16862746, 0.4509804 , 0.99215686]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8627451 , 0.25882354, 0.01568628],\n",
       "         [0.7647059 , 0.18039216, 0.        ],\n",
       "         [0.78431374, 0.20784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.5647059 , 0.14509805, 0.01960784],\n",
       "         [0.76862746, 0.22352941, 0.0627451 ],\n",
       "         [0.74509805, 0.21568628, 0.        ]],\n",
       "\n",
       "        [[0.92941177, 0.3137255 , 0.05098039],\n",
       "         [0.7647059 , 0.16078432, 0.        ],\n",
       "         [0.9137255 , 0.2901961 , 0.03529412],\n",
       "         ...,\n",
       "         [0.10588235, 0.        , 0.        ],\n",
       "         [0.5921569 , 0.13725491, 0.        ],\n",
       "         [0.6745098 , 0.21960784, 0.01960784]],\n",
       "\n",
       "        [[0.83137256, 0.20392157, 0.        ],\n",
       "         [0.9647059 , 0.32941177, 0.01176471],\n",
       "         [0.78431374, 0.18431373, 0.01176471],\n",
       "         ...,\n",
       "         [0.7921569 , 0.29803923, 0.14117648],\n",
       "         [0.3764706 , 0.10196079, 0.0627451 ],\n",
       "         [0.6784314 , 0.18431373, 0.03529412]]],\n",
       "\n",
       "\n",
       "       [[[0.3764706 , 0.32156864, 0.3882353 ],\n",
       "         [0.38431373, 0.31764707, 0.3882353 ],\n",
       "         [0.38431373, 0.32941177, 0.38039216],\n",
       "         ...,\n",
       "         [0.42352942, 0.4392157 , 0.5372549 ],\n",
       "         [0.42352942, 0.44705883, 0.54901963],\n",
       "         [0.41960785, 0.44313726, 0.54509807]],\n",
       "\n",
       "        [[0.3764706 , 0.32156864, 0.38039216],\n",
       "         [0.3882353 , 0.32156864, 0.38431373],\n",
       "         [0.38431373, 0.32941177, 0.38039216],\n",
       "         ...,\n",
       "         [0.42745098, 0.4509804 , 0.5529412 ],\n",
       "         [0.41568628, 0.44313726, 0.5529412 ],\n",
       "         [0.41568628, 0.44313726, 0.5529412 ]],\n",
       "\n",
       "        [[0.38431373, 0.3372549 , 0.39215687],\n",
       "         [0.38431373, 0.32941177, 0.3882353 ],\n",
       "         [0.39215687, 0.3372549 , 0.3882353 ],\n",
       "         ...,\n",
       "         [0.40392157, 0.4392157 , 0.5529412 ],\n",
       "         [0.40392157, 0.4392157 , 0.5529412 ],\n",
       "         [0.40392157, 0.4392157 , 0.5529412 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.53333336, 0.24313726, 0.09019608],\n",
       "         [0.5411765 , 0.22745098, 0.08235294],\n",
       "         [0.5647059 , 0.2509804 , 0.04313726],\n",
       "         ...,\n",
       "         [0.49411765, 0.14117648, 0.        ],\n",
       "         [0.4509804 , 0.13333334, 0.01568628],\n",
       "         [0.59607846, 0.23529412, 0.08235294]],\n",
       "\n",
       "        [[0.50980395, 0.21176471, 0.07058824],\n",
       "         [0.49803922, 0.21176471, 0.07450981],\n",
       "         [0.46666667, 0.20784314, 0.07450981],\n",
       "         ...,\n",
       "         [0.4392157 , 0.13725491, 0.06666667],\n",
       "         [0.4392157 , 0.1254902 , 0.01960784],\n",
       "         [0.47843137, 0.14901961, 0.00784314]],\n",
       "\n",
       "        [[0.45882353, 0.20392157, 0.05490196],\n",
       "         [0.30980393, 0.08627451, 0.        ],\n",
       "         [0.30588236, 0.07450981, 0.01960784],\n",
       "         ...,\n",
       "         [0.16470589, 0.00784314, 0.        ],\n",
       "         [0.43529412, 0.13333334, 0.02352941],\n",
       "         [0.45490196, 0.1254902 , 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e224435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ResNet = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "for layer in ResNet.layers:\n",
    "    layer.trainable = False\n",
    "ResNet = Model(inputs=ResNet.inputs, outputs=ResNet.layers[-2].output)\n",
    "ResNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63a00da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ResNet.predict(x_img_train)\n",
    "features_test = ResNet.predict(x_img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65c73749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6794, 2048)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2eddce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = tf.keras.Input(shape=(2048,), name='img_input')\n",
    "title_input = tf.keras.Input(shape=(768,), name='title_input')\n",
    "des_input = tf.keras.Input(shape=(768,), name='des_input')\n",
    "\n",
    "img_feat = tf.keras.layers.Dense(768,)(img_input)\n",
    "\n",
    "x = tf.keras.layers.Concatenate(axis=1)([img_input,title_input,img_feat])\n",
    "\n",
    "name_pred = tf.keras.layers.Dense(y_one_hot.shape[1],name=\"name\")(x)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[img_input, title_input, des_input],\n",
    "    outputs=[name_pred],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a52f4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[\n",
    "        tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    ],\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b67b5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/10\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 6.2222 - accuracy: 0.1001\n",
      "Epoch 2/10\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 2.8179 - accuracy: 0.4704\n",
      "Epoch 3/10\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 1.6760 - accuracy: 0.6716\n",
      "Epoch 4/10\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 1.1471 - accuracy: 0.7696\n",
      "Epoch 5/10\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 0.8946 - accuracy: 0.8116\n",
      "Epoch 6/10\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 0.7638 - accuracy: 0.8324\n",
      "Epoch 7/10\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 0.6520 - accuracy: 0.8540\n",
      "Epoch 8/10\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 0.5861 - accuracy: 0.8683\n",
      "Epoch 9/10\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.8749\n",
      "Epoch 10/10\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 0.4945 - accuracy: 0.8856\n",
      "Required training time: 7.620794 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"Fit model on training data\")\n",
    "start = time.time()\n",
    "history = model.fit(\n",
    "    [features,x_title_train,x_des_train],\n",
    "    y_one_hot_train,\n",
    "    batch_size=20,\n",
    "    epochs=10,\n",
    ")\n",
    "end = time.time()\n",
    "print(\"Required training time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a96d8c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 1ms/step - loss: 0.8061 - accuracy: 0.8393\n",
      "Required duration: 0.294062 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "results = model.evaluate(\n",
    "    [features_test,x_title_test,x_des_test], \n",
    "    y_one_hot_test, \n",
    "    batch_size=10)\n",
    "end = time.time()\n",
    "print(\"Required duration: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6f08a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 579us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       1.00      1.00      1.00         3\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.50      1.00      0.67         2\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       1.00      1.00      1.00         3\n",
      "          12       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         3\n",
      "          15       1.00      1.00      1.00         4\n",
      "          16       0.00      0.00      0.00         0\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       1.00      1.00      1.00         1\n",
      "          23       0.67      0.67      0.67         3\n",
      "          24       1.00      1.00      1.00         1\n",
      "          25       1.00      1.00      1.00         1\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       0.50      1.00      0.67         1\n",
      "          28       1.00      0.25      0.40         4\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         2\n",
      "          32       0.40      1.00      0.57         4\n",
      "          33       1.00      0.25      0.40         4\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      0.50      0.67         2\n",
      "          40       0.00      0.00      0.00         3\n",
      "          41       1.00      1.00      1.00         1\n",
      "          42       1.00      1.00      1.00         2\n",
      "          43       1.00      1.00      1.00         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       1.00      1.00      1.00         4\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       1.00      1.00      1.00         2\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       1.00      1.00      1.00         1\n",
      "          54       1.00      1.00      1.00         1\n",
      "          56       1.00      1.00      1.00         3\n",
      "          57       1.00      1.00      1.00         1\n",
      "          58       1.00      1.00      1.00         1\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         3\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      1.00      1.00         3\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       1.00      1.00      1.00         2\n",
      "          67       1.00      1.00      1.00         4\n",
      "          68       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       1.00      1.00      1.00         3\n",
      "          72       1.00      1.00      1.00         5\n",
      "          73       1.00      1.00      1.00         2\n",
      "          74       1.00      1.00      1.00         4\n",
      "          75       1.00      1.00      1.00         2\n",
      "          76       1.00      1.00      1.00         1\n",
      "          77       1.00      1.00      1.00         4\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         3\n",
      "          82       1.00      1.00      1.00         1\n",
      "          83       1.00      1.00      1.00         3\n",
      "          84       0.00      0.00      0.00         1\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       1.00      1.00      1.00         3\n",
      "          87       0.00      0.00      0.00         3\n",
      "          88       1.00      1.00      1.00         1\n",
      "          89       1.00      1.00      1.00         1\n",
      "          90       1.00      1.00      1.00         3\n",
      "          91       1.00      1.00      1.00         3\n",
      "          92       1.00      1.00      1.00         4\n",
      "          93       1.00      1.00      1.00         1\n",
      "          94       1.00      1.00      1.00         3\n",
      "          96       1.00      1.00      1.00         3\n",
      "          97       1.00      1.00      1.00         4\n",
      "          98       1.00      1.00      1.00         3\n",
      "          99       0.00      0.00      0.00         0\n",
      "         101       1.00      1.00      1.00         2\n",
      "         102       1.00      1.00      1.00         4\n",
      "         103       1.00      1.00      1.00         3\n",
      "         104       1.00      1.00      1.00         2\n",
      "         105       1.00      1.00      1.00         3\n",
      "         106       1.00      1.00      1.00         2\n",
      "         107       1.00      1.00      1.00         2\n",
      "         108       1.00      1.00      1.00         1\n",
      "         109       1.00      1.00      1.00         1\n",
      "         110       1.00      1.00      1.00         5\n",
      "         111       1.00      1.00      1.00         4\n",
      "         112       1.00      1.00      1.00         1\n",
      "         113       0.00      0.00      0.00         5\n",
      "         114       1.00      1.00      1.00         2\n",
      "         115       1.00      1.00      1.00         2\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       1.00      1.00      1.00         1\n",
      "         119       0.33      1.00      0.50         2\n",
      "         120       1.00      1.00      1.00         8\n",
      "         121       1.00      1.00      1.00         1\n",
      "         122       1.00      1.00      1.00         1\n",
      "         124       1.00      1.00      1.00         2\n",
      "         126       1.00      1.00      1.00         2\n",
      "         127       1.00      1.00      1.00         2\n",
      "         128       0.00      0.00      0.00         2\n",
      "         129       1.00      1.00      1.00         2\n",
      "         130       1.00      1.00      1.00         1\n",
      "         131       1.00      1.00      1.00         2\n",
      "         132       1.00      1.00      1.00         2\n",
      "         133       1.00      1.00      1.00         1\n",
      "         134       1.00      1.00      1.00         2\n",
      "         135       1.00      1.00      1.00         1\n",
      "         136       1.00      1.00      1.00         3\n",
      "         137       1.00      1.00      1.00         1\n",
      "         138       0.00      0.00      0.00         3\n",
      "         139       1.00      1.00      1.00         2\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       1.00      1.00      1.00         1\n",
      "         144       1.00      1.00      1.00         1\n",
      "         145       1.00      1.00      1.00         1\n",
      "         146       1.00      1.00      1.00         2\n",
      "         147       1.00      1.00      1.00         3\n",
      "         148       1.00      1.00      1.00         6\n",
      "         149       0.00      0.00      0.00         1\n",
      "         150       0.00      0.00      0.00         3\n",
      "         151       1.00      1.00      1.00         1\n",
      "         152       1.00      1.00      1.00         1\n",
      "         154       1.00      1.00      1.00         1\n",
      "         155       1.00      1.00      1.00         2\n",
      "         156       1.00      1.00      1.00         1\n",
      "         157       1.00      1.00      1.00         2\n",
      "         159       1.00      1.00      1.00         1\n",
      "         160       1.00      1.00      1.00         1\n",
      "         162       1.00      1.00      1.00         3\n",
      "         164       1.00      1.00      1.00         2\n",
      "         165       1.00      1.00      1.00         2\n",
      "         166       1.00      0.75      0.86         4\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       1.00      0.67      0.80         3\n",
      "         170       0.75      1.00      0.86         3\n",
      "         171       0.50      1.00      0.67         4\n",
      "         172       0.00      0.00      0.00         0\n",
      "         174       1.00      1.00      1.00         3\n",
      "         175       1.00      1.00      1.00         1\n",
      "         176       1.00      1.00      1.00         2\n",
      "         177       1.00      1.00      1.00         3\n",
      "         178       1.00      1.00      1.00         2\n",
      "         179       1.00      1.00      1.00         3\n",
      "         181       1.00      1.00      1.00         2\n",
      "         182       1.00      0.50      0.67         2\n",
      "         183       1.00      1.00      1.00         4\n",
      "         184       0.50      1.00      0.67         2\n",
      "         185       1.00      1.00      1.00         1\n",
      "         187       1.00      1.00      1.00         1\n",
      "         188       1.00      1.00      1.00         3\n",
      "         189       1.00      1.00      1.00         3\n",
      "         190       1.00      1.00      1.00         4\n",
      "         191       1.00      1.00      1.00         1\n",
      "         193       0.67      1.00      0.80         2\n",
      "         194       1.00      1.00      1.00         1\n",
      "         195       0.29      1.00      0.44         2\n",
      "         196       1.00      1.00      1.00         3\n",
      "         197       1.00      1.00      1.00         2\n",
      "         198       1.00      1.00      1.00         1\n",
      "         199       1.00      1.00      1.00         2\n",
      "         201       1.00      1.00      1.00         3\n",
      "         202       1.00      1.00      1.00         3\n",
      "         205       1.00      1.00      1.00         3\n",
      "         206       1.00      1.00      1.00         2\n",
      "         207       1.00      1.00      1.00         2\n",
      "         208       1.00      1.00      1.00         3\n",
      "         209       1.00      1.00      1.00         3\n",
      "         212       0.00      0.00      0.00         5\n",
      "         215       0.00      0.00      0.00         1\n",
      "         217       1.00      1.00      1.00         1\n",
      "         218       0.00      0.00      0.00         3\n",
      "         220       1.00      1.00      1.00         2\n",
      "         221       1.00      1.00      1.00         3\n",
      "         222       1.00      1.00      1.00         1\n",
      "         223       0.17      1.00      0.29         1\n",
      "         224       0.00      0.00      0.00         3\n",
      "         225       1.00      1.00      1.00         2\n",
      "         226       1.00      1.00      1.00         1\n",
      "         227       1.00      1.00      1.00         1\n",
      "         228       1.00      1.00      1.00         1\n",
      "         229       1.00      1.00      1.00         1\n",
      "         230       0.00      0.00      0.00         2\n",
      "         231       0.00      0.00      0.00         1\n",
      "         232       1.00      1.00      1.00         1\n",
      "         233       1.00      1.00      1.00         2\n",
      "         234       1.00      1.00      1.00         2\n",
      "         235       1.00      1.00      1.00         1\n",
      "         237       1.00      1.00      1.00         1\n",
      "         238       1.00      1.00      1.00         3\n",
      "         239       1.00      1.00      1.00         2\n",
      "         240       1.00      1.00      1.00         1\n",
      "         241       1.00      1.00      1.00         4\n",
      "         242       1.00      1.00      1.00         1\n",
      "         244       1.00      1.00      1.00         2\n",
      "         245       0.00      0.00      0.00         2\n",
      "         247       1.00      1.00      1.00         1\n",
      "         248       1.00      1.00      1.00         1\n",
      "         249       1.00      1.00      1.00         2\n",
      "         250       1.00      1.00      1.00         1\n",
      "         251       1.00      1.00      1.00         1\n",
      "         252       1.00      1.00      1.00         1\n",
      "         253       1.00      1.00      1.00         2\n",
      "         254       1.00      1.00      1.00         1\n",
      "         256       1.00      1.00      1.00         1\n",
      "         258       1.00      1.00      1.00         2\n",
      "         259       1.00      1.00      1.00         1\n",
      "         260       1.00      1.00      1.00         2\n",
      "         261       1.00      1.00      1.00         1\n",
      "         262       1.00      1.00      1.00         1\n",
      "         263       1.00      1.00      1.00         1\n",
      "         264       1.00      1.00      1.00         4\n",
      "         265       1.00      1.00      1.00         1\n",
      "         266       1.00      1.00      1.00         1\n",
      "         267       0.00      0.00      0.00         1\n",
      "         268       1.00      1.00      1.00         4\n",
      "         269       1.00      1.00      1.00         1\n",
      "         270       1.00      1.00      1.00         1\n",
      "         271       1.00      1.00      1.00         1\n",
      "         272       1.00      1.00      1.00         2\n",
      "         273       1.00      1.00      1.00         1\n",
      "         274       1.00      1.00      1.00         4\n",
      "         275       1.00      1.00      1.00         1\n",
      "         276       1.00      1.00      1.00         1\n",
      "         277       1.00      1.00      1.00         2\n",
      "         278       1.00      1.00      1.00         2\n",
      "         280       1.00      1.00      1.00         1\n",
      "         281       1.00      1.00      1.00         1\n",
      "         284       1.00      0.67      0.80         3\n",
      "         285       0.00      0.00      0.00         5\n",
      "         286       1.00      1.00      1.00         5\n",
      "         288       0.00      0.00      0.00         2\n",
      "         289       1.00      1.00      1.00         3\n",
      "         290       1.00      1.00      1.00         1\n",
      "         291       1.00      1.00      1.00         2\n",
      "         292       1.00      1.00      1.00         5\n",
      "         293       1.00      1.00      1.00         2\n",
      "         294       1.00      1.00      1.00         1\n",
      "         295       1.00      1.00      1.00         3\n",
      "         296       1.00      1.00      1.00         1\n",
      "         297       1.00      1.00      1.00         2\n",
      "         298       1.00      1.00      1.00         2\n",
      "         299       1.00      1.00      1.00         1\n",
      "         300       0.02      1.00      0.04         3\n",
      "         302       1.00      1.00      1.00         2\n",
      "         304       0.00      0.00      0.00         3\n",
      "         305       0.00      0.00      0.00         5\n",
      "         306       1.00      1.00      1.00         1\n",
      "         307       1.00      1.00      1.00         1\n",
      "         308       1.00      1.00      1.00         4\n",
      "         309       1.00      1.00      1.00         2\n",
      "         311       1.00      1.00      1.00         1\n",
      "         312       0.50      1.00      0.67         1\n",
      "         313       1.00      1.00      1.00         6\n",
      "         315       1.00      1.00      1.00         1\n",
      "         316       0.40      0.33      0.36         6\n",
      "         317       1.00      1.00      1.00         2\n",
      "         318       1.00      1.00      1.00         1\n",
      "         320       1.00      1.00      1.00         1\n",
      "         321       1.00      1.00      1.00         4\n",
      "         322       1.00      1.00      1.00         2\n",
      "         323       1.00      1.00      1.00         3\n",
      "         324       1.00      1.00      1.00         1\n",
      "         325       1.00      1.00      1.00         3\n",
      "         326       1.00      1.00      1.00         1\n",
      "         328       0.00      0.00      0.00         3\n",
      "         329       1.00      1.00      1.00         3\n",
      "         330       0.50      1.00      0.67         2\n",
      "         331       1.00      1.00      1.00         2\n",
      "         332       1.00      1.00      1.00         1\n",
      "         333       0.00      0.00      0.00         4\n",
      "         334       1.00      1.00      1.00         1\n",
      "         335       1.00      1.00      1.00         2\n",
      "         336       0.00      0.00      0.00         2\n",
      "         338       1.00      1.00      1.00         2\n",
      "         339       1.00      1.00      1.00         1\n",
      "         341       1.00      1.00      1.00         1\n",
      "         342       1.00      1.00      1.00         2\n",
      "         343       1.00      0.67      0.80         3\n",
      "         344       1.00      1.00      1.00         1\n",
      "         345       1.00      1.00      1.00         1\n",
      "         346       0.00      0.00      0.00         2\n",
      "         347       1.00      1.00      1.00         2\n",
      "         348       1.00      1.00      1.00         2\n",
      "         349       1.00      1.00      1.00         1\n",
      "         350       1.00      1.00      1.00         2\n",
      "         351       0.00      0.00      0.00         3\n",
      "         352       1.00      1.00      1.00         1\n",
      "         353       1.00      1.00      1.00         1\n",
      "         354       1.00      1.00      1.00         2\n",
      "         355       1.00      1.00      1.00         3\n",
      "         356       1.00      1.00      1.00         1\n",
      "         357       1.00      1.00      1.00         2\n",
      "         358       0.67      1.00      0.80         2\n",
      "         360       0.00      0.00      0.00         1\n",
      "         361       0.00      0.00      0.00         1\n",
      "         363       0.00      0.00      0.00         2\n",
      "         364       1.00      1.00      1.00         1\n",
      "         365       0.50      1.00      0.67         2\n",
      "         366       0.50      1.00      0.67         1\n",
      "         368       0.00      0.00      0.00         2\n",
      "         369       1.00      1.00      1.00         1\n",
      "         373       1.00      1.00      1.00         2\n",
      "         374       1.00      1.00      1.00         2\n",
      "         375       1.00      1.00      1.00         2\n",
      "         376       1.00      1.00      1.00         1\n",
      "         377       1.00      1.00      1.00         3\n",
      "         378       1.00      1.00      1.00         2\n",
      "         379       1.00      1.00      1.00         2\n",
      "         380       1.00      1.00      1.00         4\n",
      "         381       1.00      1.00      1.00         3\n",
      "         382       0.00      0.00      0.00         0\n",
      "         383       1.00      1.00      1.00         1\n",
      "         384       1.00      1.00      1.00         2\n",
      "         385       1.00      1.00      1.00         2\n",
      "         386       1.00      1.00      1.00         3\n",
      "         387       1.00      1.00      1.00         2\n",
      "         388       1.00      1.00      1.00         3\n",
      "         389       0.00      0.00      0.00         3\n",
      "         391       1.00      1.00      1.00         1\n",
      "         392       1.00      1.00      1.00         2\n",
      "         393       1.00      1.00      1.00         2\n",
      "         394       1.00      1.00      1.00         4\n",
      "         395       1.00      1.00      1.00         1\n",
      "         397       1.00      1.00      1.00         1\n",
      "         398       1.00      1.00      1.00         2\n",
      "         399       0.00      0.00      0.00         1\n",
      "         400       1.00      1.00      1.00         1\n",
      "         401       1.00      1.00      1.00         2\n",
      "         402       1.00      1.00      1.00         1\n",
      "         403       1.00      1.00      1.00         4\n",
      "         404       1.00      1.00      1.00         1\n",
      "         405       1.00      1.00      1.00         1\n",
      "         406       0.00      0.00      0.00         3\n",
      "         407       1.00      1.00      1.00         1\n",
      "         408       1.00      1.00      1.00         2\n",
      "         409       1.00      1.00      1.00         3\n",
      "         410       0.50      1.00      0.67         1\n",
      "         411       1.00      1.00      1.00         3\n",
      "         412       0.00      0.00      0.00         2\n",
      "         413       1.00      1.00      1.00         1\n",
      "         414       1.00      1.00      1.00         2\n",
      "         415       1.00      1.00      1.00         3\n",
      "         416       1.00      1.00      1.00         2\n",
      "         417       1.00      1.00      1.00         3\n",
      "         418       1.00      1.00      1.00         2\n",
      "         419       1.00      1.00      1.00         1\n",
      "         420       1.00      1.00      1.00         1\n",
      "         422       1.00      1.00      1.00         2\n",
      "         424       1.00      1.00      1.00         1\n",
      "         425       1.00      1.00      1.00         2\n",
      "         426       1.00      1.00      1.00         1\n",
      "         427       1.00      1.00      1.00         1\n",
      "         429       1.00      1.00      1.00         4\n",
      "         430       1.00      1.00      1.00         2\n",
      "         431       0.33      1.00      0.50         2\n",
      "         432       0.00      0.00      0.00         1\n",
      "         433       1.00      1.00      1.00         2\n",
      "         434       1.00      1.00      1.00         2\n",
      "         435       1.00      1.00      1.00         6\n",
      "         437       1.00      1.00      1.00         1\n",
      "         438       0.00      0.00      0.00         1\n",
      "         439       1.00      1.00      1.00         1\n",
      "         440       1.00      1.00      1.00         2\n",
      "         441       1.00      1.00      1.00         2\n",
      "         442       1.00      1.00      1.00         2\n",
      "         443       1.00      1.00      1.00         1\n",
      "         444       1.00      1.00      1.00         1\n",
      "         445       1.00      0.50      0.67         2\n",
      "         446       1.00      1.00      1.00         2\n",
      "         447       1.00      1.00      1.00         1\n",
      "         448       1.00      1.00      1.00         3\n",
      "         449       0.00      0.00      0.00         2\n",
      "         450       1.00      1.00      1.00         4\n",
      "         451       1.00      1.00      1.00         1\n",
      "         452       1.00      1.00      1.00         1\n",
      "         454       1.00      1.00      1.00         3\n",
      "         455       1.00      1.00      1.00         1\n",
      "         456       1.00      1.00      1.00         1\n",
      "         457       1.00      1.00      1.00         2\n",
      "         458       1.00      1.00      1.00         3\n",
      "         459       1.00      1.00      1.00         3\n",
      "         460       1.00      1.00      1.00         1\n",
      "         461       1.00      1.00      1.00         3\n",
      "         462       1.00      1.00      1.00         1\n",
      "         463       1.00      1.00      1.00         4\n",
      "         467       1.00      1.00      1.00         1\n",
      "         469       1.00      1.00      1.00         3\n",
      "         470       0.00      0.00      0.00         2\n",
      "         471       1.00      1.00      1.00         1\n",
      "         472       1.00      1.00      1.00         2\n",
      "         473       1.00      1.00      1.00         1\n",
      "         474       0.00      0.00      0.00         1\n",
      "         475       1.00      1.00      1.00         1\n",
      "         476       1.00      1.00      1.00         1\n",
      "         477       1.00      1.00      1.00         1\n",
      "         478       1.00      1.00      1.00         3\n",
      "         479       1.00      1.00      1.00         2\n",
      "         480       1.00      1.00      1.00         1\n",
      "         481       1.00      1.00      1.00         1\n",
      "         482       1.00      1.00      1.00         2\n",
      "         483       1.00      1.00      1.00         2\n",
      "         484       1.00      1.00      1.00         2\n",
      "         486       1.00      1.00      1.00         4\n",
      "         487       0.00      0.00      0.00         1\n",
      "         488       1.00      1.00      1.00         2\n",
      "         489       0.00      0.00      0.00         4\n",
      "         490       1.00      1.00      1.00         2\n",
      "         491       1.00      1.00      1.00         2\n",
      "         492       1.00      1.00      1.00         3\n",
      "         493       1.00      1.00      1.00         1\n",
      "         495       1.00      1.00      1.00         1\n",
      "         496       0.00      0.00      0.00         2\n",
      "         498       1.00      1.00      1.00         1\n",
      "         499       1.00      1.00      1.00         2\n",
      "         500       1.00      1.00      1.00         2\n",
      "         501       1.00      1.00      1.00         2\n",
      "         502       1.00      1.00      1.00         2\n",
      "         503       1.00      1.00      1.00         3\n",
      "         504       1.00      1.00      1.00         1\n",
      "         505       1.00      1.00      1.00         2\n",
      "         507       1.00      1.00      1.00         2\n",
      "         508       1.00      1.00      1.00         1\n",
      "         509       0.25      1.00      0.40         1\n",
      "         510       1.00      1.00      1.00         1\n",
      "         511       1.00      1.00      1.00         1\n",
      "         512       0.00      0.00      0.00         3\n",
      "         513       1.00      1.00      1.00         4\n",
      "         514       1.00      1.00      1.00         1\n",
      "         515       1.00      1.00      1.00         1\n",
      "         516       0.00      0.00      0.00         2\n",
      "         517       1.00      1.00      1.00         3\n",
      "         519       1.00      1.00      1.00         2\n",
      "         520       0.22      1.00      0.36         2\n",
      "         521       1.00      1.00      1.00         1\n",
      "         522       0.20      1.00      0.33         1\n",
      "         523       1.00      1.00      1.00         3\n",
      "         524       1.00      1.00      1.00         1\n",
      "         525       0.00      0.00      0.00         0\n",
      "         526       1.00      1.00      1.00         1\n",
      "         527       1.00      1.00      1.00         1\n",
      "         528       1.00      1.00      1.00         1\n",
      "         530       1.00      1.00      1.00         1\n",
      "         531       1.00      1.00      1.00         2\n",
      "         532       0.00      0.00      0.00         4\n",
      "         533       1.00      1.00      1.00         1\n",
      "         534       1.00      1.00      1.00         1\n",
      "         535       1.00      1.00      1.00         3\n",
      "         536       1.00      1.00      1.00         3\n",
      "         537       0.60      1.00      0.75         3\n",
      "         538       0.00      0.00      0.00         3\n",
      "         539       1.00      1.00      1.00         2\n",
      "         540       1.00      1.00      1.00         1\n",
      "         541       0.00      0.00      0.00         5\n",
      "         542       1.00      1.00      1.00         2\n",
      "         544       1.00      1.00      1.00         2\n",
      "         545       1.00      1.00      1.00         1\n",
      "         546       1.00      1.00      1.00         3\n",
      "         547       1.00      1.00      1.00         2\n",
      "         548       1.00      1.00      1.00         2\n",
      "         549       1.00      1.00      1.00         2\n",
      "         550       0.00      0.00      0.00         1\n",
      "         551       1.00      1.00      1.00         1\n",
      "         553       1.00      1.00      1.00         1\n",
      "         554       1.00      1.00      1.00         2\n",
      "         555       1.00      1.00      1.00         1\n",
      "         556       1.00      1.00      1.00         2\n",
      "         557       0.00      0.00      0.00         1\n",
      "         558       0.00      0.00      0.00         1\n",
      "         559       1.00      1.00      1.00         1\n",
      "         560       1.00      1.00      1.00         2\n",
      "         561       1.00      1.00      1.00         3\n",
      "         562       1.00      1.00      1.00         2\n",
      "         564       0.75      1.00      0.86         3\n",
      "         565       1.00      1.00      1.00         1\n",
      "         566       1.00      1.00      1.00         2\n",
      "         568       1.00      1.00      1.00         3\n",
      "         569       1.00      0.50      0.67         2\n",
      "         570       1.00      1.00      1.00         2\n",
      "         571       1.00      1.00      1.00         3\n",
      "         573       1.00      1.00      1.00         4\n",
      "         574       1.00      1.00      1.00         1\n",
      "         575       1.00      1.00      1.00         1\n",
      "         576       1.00      1.00      1.00         1\n",
      "         577       1.00      1.00      1.00         3\n",
      "         578       0.00      0.00      0.00         3\n",
      "         579       1.00      1.00      1.00         1\n",
      "         580       1.00      1.00      1.00         3\n",
      "         581       0.00      0.00      0.00         1\n",
      "         582       1.00      1.00      1.00         2\n",
      "         584       1.00      1.00      1.00         2\n",
      "         585       0.00      0.00      0.00         2\n",
      "         586       1.00      1.00      1.00         1\n",
      "         587       1.00      1.00      1.00         2\n",
      "         588       1.00      1.00      1.00         2\n",
      "         589       0.00      0.00      0.00         1\n",
      "         590       1.00      1.00      1.00         1\n",
      "         591       1.00      1.00      1.00         2\n",
      "         592       1.00      1.00      1.00         1\n",
      "         593       1.00      1.00      1.00         1\n",
      "         594       1.00      1.00      1.00         2\n",
      "         596       0.67      1.00      0.80         2\n",
      "         597       1.00      1.00      1.00         2\n",
      "         598       1.00      1.00      1.00         4\n",
      "         599       1.00      1.00      1.00         1\n",
      "         600       1.00      1.00      1.00         1\n",
      "         601       0.00      0.00      0.00         5\n",
      "         602       1.00      1.00      1.00         3\n",
      "         603       1.00      1.00      1.00         1\n",
      "         605       1.00      1.00      1.00         2\n",
      "         606       0.50      1.00      0.67         2\n",
      "         607       0.00      0.00      0.00         3\n",
      "         608       0.00      0.00      0.00         2\n",
      "         610       1.00      1.00      1.00         3\n",
      "         611       1.00      1.00      1.00         4\n",
      "         612       1.00      1.00      1.00         1\n",
      "         615       1.00      1.00      1.00         2\n",
      "         616       1.00      1.00      1.00         2\n",
      "         618       1.00      1.00      1.00         1\n",
      "         619       1.00      1.00      1.00         2\n",
      "         620       1.00      1.00      1.00         1\n",
      "         621       1.00      1.00      1.00         3\n",
      "         622       1.00      1.00      1.00         2\n",
      "         624       1.00      1.00      1.00         1\n",
      "         625       0.00      0.00      0.00         1\n",
      "         626       1.00      1.00      1.00         1\n",
      "         627       1.00      1.00      1.00         1\n",
      "         628       1.00      1.00      1.00         1\n",
      "         629       1.00      1.00      1.00         1\n",
      "         631       1.00      1.00      1.00         4\n",
      "         632       0.00      0.00      0.00         3\n",
      "         633       0.50      1.00      0.67         1\n",
      "         634       1.00      0.50      0.67         2\n",
      "         635       1.00      1.00      1.00         2\n",
      "         638       1.00      1.00      1.00         1\n",
      "         639       1.00      1.00      1.00         3\n",
      "         641       1.00      1.00      1.00         2\n",
      "         642       1.00      1.00      1.00         3\n",
      "         643       1.00      1.00      1.00         1\n",
      "         644       1.00      1.00      1.00         3\n",
      "         645       1.00      1.00      1.00         1\n",
      "         646       1.00      1.00      1.00         1\n",
      "         647       1.00      1.00      1.00         1\n",
      "         648       1.00      1.00      1.00         2\n",
      "         649       1.00      1.00      1.00         1\n",
      "         650       1.00      1.00      1.00         2\n",
      "         651       1.00      1.00      1.00         1\n",
      "         652       1.00      1.00      1.00         1\n",
      "         653       1.00      1.00      1.00         2\n",
      "         654       1.00      1.00      1.00         2\n",
      "         656       1.00      1.00      1.00         1\n",
      "         658       1.00      1.00      1.00         2\n",
      "         659       1.00      1.00      1.00         3\n",
      "         660       1.00      1.00      1.00         2\n",
      "         662       1.00      1.00      1.00         1\n",
      "         663       1.00      1.00      1.00         5\n",
      "         664       1.00      1.00      1.00         1\n",
      "         665       0.00      0.00      0.00         1\n",
      "         666       1.00      1.00      1.00         1\n",
      "         667       1.00      1.00      1.00         2\n",
      "         668       1.00      1.00      1.00         3\n",
      "         669       1.00      1.00      1.00         2\n",
      "         670       1.00      1.00      1.00         1\n",
      "         671       1.00      1.00      1.00         2\n",
      "         672       1.00      1.00      1.00         2\n",
      "         673       1.00      1.00      1.00         1\n",
      "         674       0.00      0.00      0.00         1\n",
      "         675       1.00      1.00      1.00         4\n",
      "         677       1.00      1.00      1.00         1\n",
      "         678       0.00      0.00      0.00         1\n",
      "         679       0.00      0.00      0.00         1\n",
      "         680       0.00      0.00      0.00         1\n",
      "         681       0.00      0.00      0.00         1\n",
      "         682       0.50      1.00      0.67         1\n",
      "         683       1.00      1.00      1.00         3\n",
      "         684       1.00      1.00      1.00         2\n",
      "         685       1.00      1.00      1.00         1\n",
      "         686       1.00      1.00      1.00         2\n",
      "         688       0.00      0.00      0.00         2\n",
      "         689       1.00      1.00      1.00         4\n",
      "         690       1.00      1.00      1.00         3\n",
      "         691       1.00      1.00      1.00         1\n",
      "         693       1.00      1.00      1.00         3\n",
      "         694       1.00      1.00      1.00         1\n",
      "         695       0.00      0.00      0.00         4\n",
      "         696       1.00      1.00      1.00         2\n",
      "         697       1.00      1.00      1.00         1\n",
      "         698       1.00      1.00      1.00         1\n",
      "         699       1.00      1.00      1.00         2\n",
      "         700       1.00      1.00      1.00         1\n",
      "         701       1.00      1.00      1.00         1\n",
      "         702       1.00      1.00      1.00         1\n",
      "         703       1.00      1.00      1.00         3\n",
      "         704       0.33      1.00      0.50         1\n",
      "         705       1.00      1.00      1.00         1\n",
      "         707       1.00      1.00      1.00         2\n",
      "         708       0.00      0.00      0.00         2\n",
      "         710       1.00      1.00      1.00         2\n",
      "         711       1.00      1.00      1.00         2\n",
      "         712       1.00      1.00      1.00         1\n",
      "         713       1.00      1.00      1.00         2\n",
      "         714       1.00      1.00      1.00         2\n",
      "         715       1.00      1.00      1.00         2\n",
      "         716       1.00      1.00      1.00         1\n",
      "         717       1.00      1.00      1.00         1\n",
      "         718       1.00      1.00      1.00         3\n",
      "         719       1.00      1.00      1.00         2\n",
      "         721       0.00      0.00      0.00         3\n",
      "         722       1.00      1.00      1.00         4\n",
      "         724       1.00      1.00      1.00         4\n",
      "         725       0.67      1.00      0.80         2\n",
      "         727       0.00      0.00      0.00         2\n",
      "         728       1.00      1.00      1.00         2\n",
      "         729       1.00      1.00      1.00         2\n",
      "         730       1.00      1.00      1.00         1\n",
      "         732       0.50      1.00      0.67         4\n",
      "         733       0.00      0.00      0.00         4\n",
      "         734       1.00      1.00      1.00         1\n",
      "         736       1.00      1.00      1.00         1\n",
      "         737       1.00      1.00      1.00         2\n",
      "         738       0.00      0.00      0.00         1\n",
      "         740       1.00      1.00      1.00         2\n",
      "         741       1.00      1.00      1.00         3\n",
      "         743       1.00      1.00      1.00         2\n",
      "         744       1.00      1.00      1.00         3\n",
      "         745       1.00      1.00      1.00         1\n",
      "         746       1.00      1.00      1.00         1\n",
      "         747       1.00      1.00      1.00         2\n",
      "         748       1.00      1.00      1.00         2\n",
      "         749       1.00      1.00      1.00         1\n",
      "         752       0.00      0.00      0.00         3\n",
      "         753       0.00      0.00      0.00         0\n",
      "         754       1.00      1.00      1.00         2\n",
      "         755       1.00      1.00      1.00         2\n",
      "         756       0.00      0.00      0.00         1\n",
      "         757       1.00      1.00      1.00         3\n",
      "         758       1.00      1.00      1.00         2\n",
      "         759       1.00      1.00      1.00         1\n",
      "         760       1.00      1.00      1.00         2\n",
      "         761       0.00      0.00      0.00         3\n",
      "         762       1.00      1.00      1.00         3\n",
      "         763       1.00      1.00      1.00         1\n",
      "         764       1.00      1.00      1.00         3\n",
      "         765       0.67      1.00      0.80         2\n",
      "         766       1.00      1.00      1.00         3\n",
      "         767       1.00      1.00      1.00         2\n",
      "         768       1.00      1.00      1.00         3\n",
      "         769       1.00      1.00      1.00         1\n",
      "         770       1.00      1.00      1.00         3\n",
      "         772       1.00      1.00      1.00         1\n",
      "         773       0.00      0.00      0.00         3\n",
      "         774       0.50      0.50      0.50         2\n",
      "         776       1.00      1.00      1.00         3\n",
      "         777       1.00      1.00      1.00         1\n",
      "         779       1.00      1.00      1.00         1\n",
      "         780       1.00      0.80      0.89         5\n",
      "         781       0.00      0.00      0.00         1\n",
      "         782       0.33      1.00      0.50         1\n",
      "         783       1.00      1.00      1.00         1\n",
      "         784       1.00      1.00      1.00         1\n",
      "         786       1.00      1.00      1.00         1\n",
      "         787       1.00      1.00      1.00         2\n",
      "         788       1.00      1.00      1.00         2\n",
      "         790       1.00      1.00      1.00         1\n",
      "         791       1.00      1.00      1.00         2\n",
      "         792       0.00      0.00      0.00         2\n",
      "         794       0.00      0.00      0.00         3\n",
      "         795       1.00      1.00      1.00         2\n",
      "         796       1.00      1.00      1.00         1\n",
      "         797       1.00      1.00      1.00         3\n",
      "         798       1.00      1.00      1.00         2\n",
      "         800       0.00      0.00      0.00         0\n",
      "         801       1.00      1.00      1.00         4\n",
      "         802       1.00      1.00      1.00         3\n",
      "         803       1.00      1.00      1.00         1\n",
      "         804       1.00      1.00      1.00         2\n",
      "         805       1.00      1.00      1.00         2\n",
      "         806       1.00      1.00      1.00         2\n",
      "         807       1.00      1.00      1.00         2\n",
      "         808       1.00      1.00      1.00         3\n",
      "         809       1.00      1.00      1.00         5\n",
      "         810       0.00      0.00      0.00         1\n",
      "         811       1.00      1.00      1.00         1\n",
      "         812       1.00      1.00      1.00         1\n",
      "         815       1.00      1.00      1.00         3\n",
      "         816       1.00      1.00      1.00         2\n",
      "         817       0.00      0.00      0.00         2\n",
      "         818       0.00      0.00      0.00         4\n",
      "         819       1.00      1.00      1.00         2\n",
      "         820       1.00      1.00      1.00         2\n",
      "         821       1.00      1.00      1.00         2\n",
      "         822       0.00      0.00      0.00         3\n",
      "         823       1.00      1.00      1.00         2\n",
      "         824       1.00      1.00      1.00         4\n",
      "         826       1.00      1.00      1.00         1\n",
      "         827       1.00      1.00      1.00         2\n",
      "         828       1.00      1.00      1.00         1\n",
      "         829       0.75      1.00      0.86         3\n",
      "         830       0.00      0.00      0.00         1\n",
      "         832       0.00      0.00      0.00         1\n",
      "         834       1.00      1.00      1.00         2\n",
      "         835       1.00      1.00      1.00         1\n",
      "         836       1.00      1.00      1.00         2\n",
      "         837       0.00      0.00      0.00         3\n",
      "         838       1.00      1.00      1.00         3\n",
      "         839       1.00      1.00      1.00         4\n",
      "         840       1.00      1.00      1.00         2\n",
      "         842       1.00      1.00      1.00         1\n",
      "         844       1.00      1.00      1.00         1\n",
      "         845       1.00      1.00      1.00         2\n",
      "         846       1.00      1.00      1.00         3\n",
      "         848       1.00      1.00      1.00         1\n",
      "         849       1.00      1.00      1.00         1\n",
      "         852       1.00      1.00      1.00         3\n",
      "         853       1.00      1.00      1.00         2\n",
      "         854       1.00      1.00      1.00         3\n",
      "         855       1.00      1.00      1.00         3\n",
      "         856       1.00      1.00      1.00         3\n",
      "         857       1.00      1.00      1.00         2\n",
      "         858       1.00      1.00      1.00         2\n",
      "         859       0.00      0.00      0.00         3\n",
      "         860       1.00      1.00      1.00         3\n",
      "         861       1.00      1.00      1.00         1\n",
      "         863       1.00      1.00      1.00         3\n",
      "         865       1.00      1.00      1.00         1\n",
      "         866       1.00      1.00      1.00         3\n",
      "         868       1.00      1.00      1.00         1\n",
      "         869       1.00      1.00      1.00         1\n",
      "         871       1.00      1.00      1.00         2\n",
      "         872       1.00      1.00      1.00         1\n",
      "         873       1.00      1.00      1.00         2\n",
      "         874       1.00      1.00      1.00         3\n",
      "         875       1.00      1.00      1.00         3\n",
      "         876       1.00      1.00      1.00         1\n",
      "         877       1.00      1.00      1.00         1\n",
      "         878       1.00      1.00      1.00         2\n",
      "         880       1.00      1.00      1.00         1\n",
      "         882       1.00      1.00      1.00         1\n",
      "         884       1.00      1.00      1.00         2\n",
      "         885       1.00      1.00      1.00         1\n",
      "         886       1.00      1.00      1.00         3\n",
      "         887       1.00      1.00      1.00         4\n",
      "         888       1.00      1.00      1.00         3\n",
      "         889       1.00      1.00      1.00         3\n",
      "         890       1.00      1.00      1.00         2\n",
      "         891       1.00      1.00      1.00         1\n",
      "         892       1.00      0.50      0.67         2\n",
      "         894       1.00      1.00      1.00         1\n",
      "         895       1.00      1.00      1.00         4\n",
      "         896       1.00      1.00      1.00         1\n",
      "         897       1.00      1.00      1.00         2\n",
      "         898       1.00      1.00      1.00         2\n",
      "         899       1.00      1.00      1.00         2\n",
      "         900       1.00      1.00      1.00         2\n",
      "         901       1.00      1.00      1.00         3\n",
      "         902       1.00      1.00      1.00         2\n",
      "         903       1.00      1.00      1.00         2\n",
      "         905       1.00      1.00      1.00         2\n",
      "         906       1.00      1.00      1.00         1\n",
      "         907       1.00      1.00      1.00         4\n",
      "         909       1.00      1.00      1.00         4\n",
      "         910       1.00      1.00      1.00         2\n",
      "         911       1.00      1.00      1.00         2\n",
      "         912       1.00      1.00      1.00         2\n",
      "         913       1.00      1.00      1.00         3\n",
      "         915       1.00      1.00      1.00         3\n",
      "         916       1.00      1.00      1.00         2\n",
      "         917       1.00      1.00      1.00         3\n",
      "         918       1.00      1.00      1.00         3\n",
      "         920       1.00      1.00      1.00         2\n",
      "         921       1.00      1.00      1.00         3\n",
      "         922       1.00      1.00      1.00         5\n",
      "         923       1.00      1.00      1.00         2\n",
      "         924       1.00      1.00      1.00         3\n",
      "         925       1.00      1.00      1.00         4\n",
      "         926       1.00      1.00      1.00         2\n",
      "         927       1.00      1.00      1.00         1\n",
      "         928       1.00      1.00      1.00         1\n",
      "         929       1.00      1.00      1.00         1\n",
      "         930       1.00      1.00      1.00         5\n",
      "         931       1.00      1.00      1.00         2\n",
      "         934       1.00      1.00      1.00         3\n",
      "         935       1.00      1.00      1.00         2\n",
      "         936       0.00      0.00      0.00         2\n",
      "         938       0.00      0.00      0.00         1\n",
      "         939       1.00      1.00      1.00         1\n",
      "         940       0.00      0.00      0.00         6\n",
      "         941       1.00      1.00      1.00         3\n",
      "         942       1.00      1.00      1.00         1\n",
      "         943       1.00      1.00      1.00         2\n",
      "         944       1.00      1.00      1.00         3\n",
      "         945       1.00      1.00      1.00         1\n",
      "         947       1.00      1.00      1.00         2\n",
      "         948       1.00      1.00      1.00         1\n",
      "         949       1.00      1.00      1.00         3\n",
      "         950       1.00      1.00      1.00         1\n",
      "         951       1.00      1.00      1.00         2\n",
      "         952       0.00      0.00      0.00         2\n",
      "         953       1.00      1.00      1.00         1\n",
      "         954       1.00      1.00      1.00         2\n",
      "         955       0.00      0.00      0.00         5\n",
      "         956       1.00      1.00      1.00         3\n",
      "         957       1.00      1.00      1.00         1\n",
      "         958       1.00      1.00      1.00         3\n",
      "         959       0.00      0.00      0.00         3\n",
      "         960       0.00      0.00      0.00         2\n",
      "         961       1.00      1.00      1.00         2\n",
      "         962       1.00      1.00      1.00         2\n",
      "         963       1.00      1.00      1.00         1\n",
      "         964       1.00      1.00      1.00         2\n",
      "         965       1.00      1.00      1.00         1\n",
      "         966       1.00      1.00      1.00         1\n",
      "         968       1.00      1.00      1.00         2\n",
      "         969       1.00      1.00      1.00         1\n",
      "         970       1.00      1.00      1.00         4\n",
      "         971       1.00      1.00      1.00         2\n",
      "         972       1.00      1.00      1.00         1\n",
      "         973       1.00      1.00      1.00         3\n",
      "         974       0.00      0.00      0.00         2\n",
      "         975       1.00      1.00      1.00         2\n",
      "         976       1.00      1.00      1.00         1\n",
      "         977       0.50      1.00      0.67         1\n",
      "         978       1.00      1.00      1.00         2\n",
      "         979       1.00      1.00      1.00         1\n",
      "         980       1.00      1.00      1.00         4\n",
      "         981       0.00      0.00      0.00         4\n",
      "         982       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.84      1699\n",
      "   macro avg       0.83      0.85      0.83      1699\n",
      "weighted avg       0.83      0.84      0.83      1699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict([features_test,x_title_test,x_des_test], batch_size=10, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_encoded_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92fe11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classification.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
